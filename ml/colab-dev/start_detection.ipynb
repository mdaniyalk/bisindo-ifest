{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import and Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "import mediapipe as mp\n",
    "from utils.detector import Detector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Call detector class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_detect = Detector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for testing\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "# Set mediapipe model \n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    while cap.isOpened():\n",
    "\n",
    "        # Read feed\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # Make detections\n",
    "        image, results = mediapipe_detection(frame, holistic)\n",
    "        print(results)\n",
    "        \n",
    "        # Draw landmarks\n",
    "        draw_styled_landmarks(image, results)\n",
    "\n",
    "        # Show to screen\n",
    "        cv2.imshow('OpenCV Feed', image)\n",
    "\n",
    "        # Break gracefully\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Setup Folders for Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path for exported data, numpy arrays\n",
    "DATA_PATH = os.path.join('Dataset_Keypoints_start_record2')\n",
    "# DATA_PATH = os.path.join('Dataset_Keypoints_Data_wo_face_sintetic') \n",
    "\n",
    "# Actions that we try to detect\n",
    "actions = np.array(['start', 'continue'])\n",
    "actions2 = np.array(['halo', 'nama', 'aku', 'perkenalkan', 'r', 'kami', 'd', 'a', 'n', 'i', 'y', 'l', 'u', 'g', 'm', 'NOTHING'])\n",
    "\n",
    "# 140 videos worth of data\n",
    "no_sequences = 150\n",
    "\n",
    "# Videos are going to be 50 frames in length\n",
    "sequence_length = 5\n",
    "\n",
    "# Folder start\n",
    "# start_folder = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for action in actions: \n",
    "# dirmax = np.max(np.array(os.listdir(os.path.join(DATA_PATH, '1'))).astype(int))\n",
    "for action in actions: \n",
    "    for sequence in range(2250):\n",
    "        try: \n",
    "            os.makedirs(os.path.join(DATA_PATH, action, str(sequence)))\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Collect Keypoint Values for Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# actions = np.array(['halo', 'nama', 'aku', 'perkenalkan', 'r', 'kami', 'd', 'a', 'n', 'i', 'y', 'l', 'u', 'g', 'm', 'NOTHING'])\n",
    "# actions = np.array(['halo'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start halo, ke 1\n",
      "start halo, ke 2\n",
      "start halo, ke 3\n",
      "start halo, ke 4\n",
      "start halo, ke 5\n",
      "start halo, ke 6\n",
      "start halo, ke 7\n",
      "start halo, ke 8\n",
      "start halo, ke 9\n",
      "start halo, ke 10\n",
      "start halo, ke 11\n",
      "start halo, ke 12\n",
      "start halo, ke 13\n",
      "start halo, ke 14\n",
      "start halo, ke 15\n",
      "start halo, ke 16\n",
      "start halo, ke 17\n",
      "start halo, ke 18\n",
      "start halo, ke 19\n",
      "start halo, ke 20\n",
      "start halo, ke 21\n",
      "start halo, ke 22\n",
      "start halo, ke 23\n",
      "start halo, ke 24\n",
      "start halo, ke 25\n",
      "start halo, ke 26\n",
      "start halo, ke 27\n",
      "start halo, ke 28\n",
      "start halo, ke 29\n",
      "start halo, ke 30\n",
      "start halo, ke 31\n",
      "start halo, ke 32\n",
      "start halo, ke 33\n",
      "start halo, ke 34\n",
      "start halo, ke 35\n",
      "start halo, ke 36\n",
      "start halo, ke 37\n",
      "start halo, ke 38\n",
      "start halo, ke 39\n",
      "start halo, ke 40\n",
      "start halo, ke 41\n",
      "start halo, ke 42\n",
      "start halo, ke 43\n",
      "start halo, ke 44\n",
      "start halo, ke 45\n",
      "start halo, ke 46\n",
      "start halo, ke 47\n",
      "start halo, ke 48\n",
      "start halo, ke 49\n",
      "start halo, ke 50\n",
      "start halo, ke 51\n",
      "start halo, ke 52\n",
      "start halo, ke 53\n",
      "start halo, ke 54\n",
      "start halo, ke 55\n",
      "start halo, ke 56\n",
      "start halo, ke 57\n",
      "start halo, ke 58\n",
      "start halo, ke 59\n",
      "start halo, ke 60\n",
      "start halo, ke 61\n",
      "start halo, ke 62\n",
      "start halo, ke 63\n",
      "start halo, ke 64\n",
      "start halo, ke 65\n",
      "start halo, ke 66\n",
      "start halo, ke 67\n",
      "start halo, ke 68\n",
      "start halo, ke 69\n",
      "start halo, ke 70\n",
      "start halo, ke 71\n",
      "start halo, ke 72\n",
      "start halo, ke 73\n",
      "start halo, ke 74\n",
      "start halo, ke 75\n",
      "start halo, ke 76\n",
      "start halo, ke 77\n",
      "start halo, ke 78\n",
      "start halo, ke 79\n",
      "start halo, ke 80\n",
      "start halo, ke 81\n",
      "start halo, ke 82\n",
      "start halo, ke 83\n",
      "start halo, ke 84\n",
      "start halo, ke 85\n",
      "start halo, ke 86\n",
      "start halo, ke 87\n",
      "start halo, ke 88\n",
      "start halo, ke 89\n",
      "start halo, ke 90\n",
      "start halo, ke 91\n",
      "start halo, ke 92\n",
      "start halo, ke 93\n",
      "start halo, ke 94\n",
      "start halo, ke 95\n",
      "start halo, ke 96\n",
      "start halo, ke 97\n",
      "start halo, ke 98\n",
      "start halo, ke 99\n",
      "start halo, ke 100\n",
      "start halo, ke 101\n",
      "start halo, ke 102\n",
      "start halo, ke 103\n",
      "start halo, ke 104\n",
      "start halo, ke 105\n",
      "start halo, ke 106\n",
      "start halo, ke 107\n",
      "start halo, ke 108\n",
      "start halo, ke 109\n",
      "start halo, ke 110\n",
      "start halo, ke 111\n",
      "start halo, ke 112\n",
      "start halo, ke 113\n",
      "start halo, ke 114\n",
      "start halo, ke 115\n",
      "start halo, ke 116\n",
      "start halo, ke 117\n",
      "start halo, ke 118\n",
      "start halo, ke 119\n",
      "start halo, ke 120\n",
      "start halo, ke 121\n",
      "start halo, ke 122\n",
      "start halo, ke 123\n",
      "start halo, ke 124\n",
      "start halo, ke 125\n",
      "start halo, ke 126\n",
      "start halo, ke 127\n",
      "start halo, ke 128\n",
      "start halo, ke 129\n",
      "start halo, ke 130\n",
      "start halo, ke 131\n",
      "start halo, ke 132\n",
      "start halo, ke 133\n",
      "start halo, ke 134\n",
      "start halo, ke 135\n",
      "start halo, ke 136\n",
      "start halo, ke 137\n",
      "start halo, ke 138\n",
      "start halo, ke 139\n",
      "start halo, ke 140\n",
      "start halo, ke 141\n",
      "start halo, ke 142\n",
      "start halo, ke 143\n",
      "start halo, ke 144\n",
      "start halo, ke 145\n",
      "start halo, ke 146\n",
      "start halo, ke 147\n",
      "start halo, ke 148\n",
      "start halo, ke 149\n",
      "start halo, ke 150\n",
      "start nama, ke 1\n",
      "start nama, ke 2\n",
      "start nama, ke 3\n",
      "start nama, ke 4\n",
      "start nama, ke 5\n",
      "start nama, ke 6\n",
      "start nama, ke 7\n",
      "start nama, ke 8\n",
      "start nama, ke 9\n",
      "start nama, ke 10\n",
      "start nama, ke 11\n",
      "start nama, ke 12\n",
      "start nama, ke 13\n",
      "start nama, ke 14\n",
      "start nama, ke 15\n",
      "start nama, ke 16\n",
      "start nama, ke 17\n",
      "start nama, ke 18\n",
      "start nama, ke 19\n",
      "start nama, ke 20\n",
      "start nama, ke 21\n",
      "start nama, ke 22\n",
      "start nama, ke 23\n",
      "start nama, ke 24\n",
      "start nama, ke 25\n",
      "start nama, ke 26\n",
      "start nama, ke 27\n",
      "start nama, ke 28\n",
      "start nama, ke 29\n",
      "start nama, ke 30\n",
      "start nama, ke 31\n",
      "start nama, ke 32\n",
      "start nama, ke 33\n",
      "start nama, ke 34\n",
      "start nama, ke 35\n",
      "start nama, ke 36\n",
      "start nama, ke 37\n",
      "start nama, ke 38\n",
      "start nama, ke 39\n",
      "start nama, ke 40\n",
      "start nama, ke 41\n",
      "start nama, ke 42\n",
      "start nama, ke 43\n",
      "start nama, ke 44\n",
      "start nama, ke 45\n",
      "start nama, ke 46\n",
      "start nama, ke 47\n",
      "start nama, ke 48\n",
      "start nama, ke 49\n",
      "start nama, ke 50\n",
      "start nama, ke 51\n",
      "start nama, ke 52\n",
      "start nama, ke 53\n",
      "start nama, ke 54\n",
      "start nama, ke 55\n",
      "start nama, ke 56\n",
      "start nama, ke 57\n",
      "start nama, ke 58\n",
      "start nama, ke 59\n",
      "start nama, ke 60\n",
      "start nama, ke 61\n",
      "start nama, ke 62\n",
      "start nama, ke 63\n",
      "start nama, ke 64\n",
      "start nama, ke 65\n",
      "start nama, ke 66\n",
      "start nama, ke 67\n",
      "start nama, ke 68\n",
      "start nama, ke 69\n",
      "start nama, ke 70\n",
      "start nama, ke 71\n",
      "start nama, ke 72\n",
      "start nama, ke 73\n",
      "start nama, ke 74\n",
      "start nama, ke 75\n",
      "start nama, ke 76\n",
      "start nama, ke 77\n",
      "start nama, ke 78\n",
      "start nama, ke 79\n",
      "start nama, ke 80\n",
      "start nama, ke 81\n",
      "start nama, ke 82\n",
      "start nama, ke 83\n",
      "start nama, ke 84\n",
      "start nama, ke 85\n",
      "start nama, ke 86\n",
      "start nama, ke 87\n",
      "start nama, ke 88\n",
      "start nama, ke 89\n",
      "start nama, ke 90\n",
      "start nama, ke 91\n",
      "start nama, ke 92\n",
      "start nama, ke 93\n",
      "start nama, ke 94\n",
      "start nama, ke 95\n",
      "start nama, ke 96\n",
      "start nama, ke 97\n",
      "start nama, ke 98\n",
      "start nama, ke 99\n",
      "start nama, ke 100\n",
      "start nama, ke 101\n",
      "start nama, ke 102\n",
      "start nama, ke 103\n",
      "start nama, ke 104\n",
      "start nama, ke 105\n",
      "start nama, ke 106\n",
      "start nama, ke 107\n",
      "start nama, ke 108\n",
      "start nama, ke 109\n",
      "start nama, ke 110\n",
      "start nama, ke 111\n",
      "start nama, ke 112\n",
      "start nama, ke 113\n",
      "start nama, ke 114\n",
      "start nama, ke 115\n",
      "start nama, ke 116\n",
      "start nama, ke 117\n",
      "start nama, ke 118\n",
      "start nama, ke 119\n",
      "start nama, ke 120\n",
      "start nama, ke 121\n",
      "start nama, ke 122\n",
      "start nama, ke 123\n",
      "start nama, ke 124\n",
      "start nama, ke 125\n",
      "start nama, ke 126\n",
      "start nama, ke 127\n",
      "start nama, ke 128\n",
      "start nama, ke 129\n",
      "start nama, ke 130\n",
      "start nama, ke 131\n",
      "start nama, ke 132\n",
      "start nama, ke 133\n",
      "start nama, ke 134\n",
      "start nama, ke 135\n",
      "start nama, ke 136\n",
      "start nama, ke 137\n",
      "start nama, ke 138\n",
      "start nama, ke 139\n",
      "start nama, ke 140\n",
      "start nama, ke 141\n",
      "start nama, ke 142\n",
      "start nama, ke 143\n",
      "start nama, ke 144\n",
      "start nama, ke 145\n",
      "start nama, ke 146\n",
      "start nama, ke 147\n",
      "start nama, ke 148\n",
      "start nama, ke 149\n",
      "start nama, ke 150\n",
      "start aku, ke 1\n",
      "start aku, ke 2\n",
      "start aku, ke 3\n",
      "start aku, ke 4\n",
      "start aku, ke 5\n",
      "start aku, ke 6\n",
      "start aku, ke 7\n",
      "start aku, ke 8\n",
      "start aku, ke 9\n",
      "start aku, ke 10\n",
      "start aku, ke 11\n",
      "start aku, ke 12\n",
      "start aku, ke 13\n",
      "start aku, ke 14\n",
      "start aku, ke 15\n",
      "start aku, ke 16\n",
      "start aku, ke 17\n",
      "start aku, ke 18\n",
      "start aku, ke 19\n",
      "start aku, ke 20\n",
      "start aku, ke 21\n",
      "start aku, ke 22\n",
      "start aku, ke 23\n",
      "start aku, ke 24\n",
      "start aku, ke 25\n",
      "start aku, ke 26\n",
      "start aku, ke 27\n",
      "start aku, ke 28\n",
      "start aku, ke 29\n",
      "start aku, ke 30\n",
      "start aku, ke 31\n",
      "start aku, ke 32\n",
      "start aku, ke 33\n",
      "start aku, ke 34\n",
      "start aku, ke 35\n",
      "start aku, ke 36\n",
      "start aku, ke 37\n",
      "start aku, ke 38\n",
      "start aku, ke 39\n",
      "start aku, ke 40\n",
      "start aku, ke 41\n",
      "start aku, ke 42\n",
      "start aku, ke 43\n",
      "start aku, ke 44\n",
      "start aku, ke 45\n",
      "start aku, ke 46\n",
      "start aku, ke 47\n",
      "start aku, ke 48\n",
      "start aku, ke 49\n",
      "start aku, ke 50\n",
      "start aku, ke 51\n",
      "start aku, ke 52\n",
      "start aku, ke 53\n",
      "start aku, ke 54\n",
      "start aku, ke 55\n",
      "start aku, ke 56\n",
      "start aku, ke 57\n",
      "start aku, ke 58\n",
      "start aku, ke 59\n",
      "start aku, ke 60\n",
      "start aku, ke 61\n",
      "start aku, ke 62\n",
      "start aku, ke 63\n",
      "start aku, ke 64\n",
      "start aku, ke 65\n",
      "start aku, ke 66\n",
      "start aku, ke 67\n",
      "start aku, ke 68\n",
      "start aku, ke 69\n",
      "start aku, ke 70\n",
      "start aku, ke 71\n",
      "start aku, ke 72\n",
      "start aku, ke 73\n",
      "start aku, ke 74\n",
      "start aku, ke 75\n",
      "start aku, ke 76\n",
      "start aku, ke 77\n",
      "start aku, ke 78\n",
      "start aku, ke 79\n",
      "start aku, ke 80\n",
      "start aku, ke 81\n",
      "start aku, ke 82\n",
      "start aku, ke 83\n",
      "start aku, ke 84\n",
      "start aku, ke 85\n",
      "start aku, ke 86\n",
      "start aku, ke 87\n",
      "start aku, ke 88\n",
      "start aku, ke 89\n",
      "start aku, ke 90\n",
      "start aku, ke 91\n",
      "start aku, ke 92\n",
      "start aku, ke 93\n",
      "start aku, ke 94\n",
      "start aku, ke 95\n",
      "start aku, ke 96\n",
      "start aku, ke 97\n",
      "start aku, ke 98\n",
      "start aku, ke 99\n",
      "start aku, ke 100\n",
      "start aku, ke 101\n",
      "start aku, ke 102\n",
      "start aku, ke 103\n",
      "start aku, ke 104\n",
      "start aku, ke 105\n",
      "start aku, ke 106\n",
      "start aku, ke 107\n",
      "start aku, ke 108\n",
      "start aku, ke 109\n",
      "start aku, ke 110\n",
      "start aku, ke 111\n",
      "start aku, ke 112\n",
      "start aku, ke 113\n",
      "start aku, ke 114\n",
      "start aku, ke 115\n",
      "start aku, ke 116\n",
      "start aku, ke 117\n",
      "start aku, ke 118\n",
      "start aku, ke 119\n",
      "start aku, ke 120\n",
      "start aku, ke 121\n",
      "start aku, ke 122\n",
      "start aku, ke 123\n",
      "start aku, ke 124\n",
      "start aku, ke 125\n",
      "start aku, ke 126\n",
      "start aku, ke 127\n",
      "start aku, ke 128\n",
      "start aku, ke 129\n",
      "start aku, ke 130\n",
      "start aku, ke 131\n",
      "start aku, ke 132\n",
      "start aku, ke 133\n",
      "start aku, ke 134\n",
      "start aku, ke 135\n",
      "start aku, ke 136\n",
      "start aku, ke 137\n",
      "start aku, ke 138\n",
      "start aku, ke 139\n",
      "start aku, ke 140\n",
      "start aku, ke 141\n",
      "start aku, ke 142\n",
      "start aku, ke 143\n",
      "start aku, ke 144\n",
      "start aku, ke 145\n",
      "start aku, ke 146\n",
      "start aku, ke 147\n",
      "start aku, ke 148\n",
      "start aku, ke 149\n",
      "start aku, ke 150\n",
      "start perkenalkan, ke 1\n",
      "start perkenalkan, ke 2\n",
      "start perkenalkan, ke 3\n",
      "start perkenalkan, ke 4\n",
      "start perkenalkan, ke 5\n",
      "start perkenalkan, ke 6\n",
      "start perkenalkan, ke 7\n",
      "start perkenalkan, ke 8\n",
      "start perkenalkan, ke 9\n",
      "start perkenalkan, ke 10\n",
      "start perkenalkan, ke 11\n",
      "start perkenalkan, ke 12\n",
      "start perkenalkan, ke 13\n",
      "start perkenalkan, ke 14\n",
      "start perkenalkan, ke 15\n",
      "start perkenalkan, ke 16\n",
      "start perkenalkan, ke 17\n",
      "start perkenalkan, ke 18\n",
      "start perkenalkan, ke 19\n",
      "start perkenalkan, ke 20\n",
      "start perkenalkan, ke 21\n",
      "start perkenalkan, ke 22\n",
      "start perkenalkan, ke 23\n",
      "start perkenalkan, ke 24\n",
      "start perkenalkan, ke 25\n",
      "start perkenalkan, ke 26\n",
      "start perkenalkan, ke 27\n",
      "start perkenalkan, ke 28\n",
      "start perkenalkan, ke 29\n",
      "start perkenalkan, ke 30\n",
      "start perkenalkan, ke 31\n",
      "start perkenalkan, ke 32\n",
      "start perkenalkan, ke 33\n",
      "start perkenalkan, ke 34\n",
      "start perkenalkan, ke 35\n",
      "start perkenalkan, ke 36\n",
      "start perkenalkan, ke 37\n",
      "start perkenalkan, ke 38\n",
      "start perkenalkan, ke 39\n",
      "start perkenalkan, ke 40\n",
      "start perkenalkan, ke 41\n",
      "start perkenalkan, ke 42\n",
      "start perkenalkan, ke 43\n",
      "start perkenalkan, ke 44\n",
      "start perkenalkan, ke 45\n",
      "start perkenalkan, ke 46\n",
      "start perkenalkan, ke 47\n",
      "start perkenalkan, ke 48\n",
      "start perkenalkan, ke 49\n",
      "start perkenalkan, ke 50\n",
      "start perkenalkan, ke 51\n",
      "start perkenalkan, ke 52\n",
      "start perkenalkan, ke 53\n",
      "start perkenalkan, ke 54\n",
      "start perkenalkan, ke 55\n",
      "start perkenalkan, ke 56\n",
      "start perkenalkan, ke 57\n",
      "start perkenalkan, ke 58\n",
      "start perkenalkan, ke 59\n",
      "start perkenalkan, ke 60\n",
      "start perkenalkan, ke 61\n",
      "start perkenalkan, ke 62\n",
      "start perkenalkan, ke 63\n",
      "start perkenalkan, ke 64\n",
      "start perkenalkan, ke 65\n",
      "start perkenalkan, ke 66\n",
      "start perkenalkan, ke 67\n",
      "start perkenalkan, ke 68\n",
      "start perkenalkan, ke 69\n",
      "start perkenalkan, ke 70\n",
      "start perkenalkan, ke 71\n",
      "start perkenalkan, ke 72\n",
      "start perkenalkan, ke 73\n",
      "start perkenalkan, ke 74\n",
      "start perkenalkan, ke 75\n",
      "start perkenalkan, ke 76\n",
      "start perkenalkan, ke 77\n",
      "start perkenalkan, ke 78\n",
      "start perkenalkan, ke 79\n",
      "start perkenalkan, ke 80\n",
      "start perkenalkan, ke 81\n",
      "start perkenalkan, ke 82\n",
      "start perkenalkan, ke 83\n",
      "start perkenalkan, ke 84\n",
      "start perkenalkan, ke 85\n",
      "start perkenalkan, ke 86\n",
      "start perkenalkan, ke 87\n",
      "start perkenalkan, ke 88\n",
      "start perkenalkan, ke 89\n",
      "start perkenalkan, ke 90\n",
      "start perkenalkan, ke 91\n",
      "start perkenalkan, ke 92\n",
      "start perkenalkan, ke 93\n",
      "start perkenalkan, ke 94\n",
      "start perkenalkan, ke 95\n",
      "start perkenalkan, ke 96\n",
      "start perkenalkan, ke 97\n",
      "start perkenalkan, ke 98\n",
      "start perkenalkan, ke 99\n",
      "start perkenalkan, ke 100\n",
      "start perkenalkan, ke 101\n",
      "start perkenalkan, ke 102\n",
      "start perkenalkan, ke 103\n",
      "start perkenalkan, ke 104\n",
      "start perkenalkan, ke 105\n",
      "start perkenalkan, ke 106\n",
      "start perkenalkan, ke 107\n",
      "start perkenalkan, ke 108\n",
      "start perkenalkan, ke 109\n",
      "start perkenalkan, ke 110\n",
      "start perkenalkan, ke 111\n",
      "start perkenalkan, ke 112\n",
      "start perkenalkan, ke 113\n",
      "start perkenalkan, ke 114\n",
      "start perkenalkan, ke 115\n",
      "start perkenalkan, ke 116\n",
      "start perkenalkan, ke 117\n",
      "start perkenalkan, ke 118\n",
      "start perkenalkan, ke 119\n",
      "start perkenalkan, ke 120\n",
      "start perkenalkan, ke 121\n",
      "start perkenalkan, ke 122\n",
      "start perkenalkan, ke 123\n",
      "start perkenalkan, ke 124\n",
      "start perkenalkan, ke 125\n",
      "start perkenalkan, ke 126\n",
      "start perkenalkan, ke 127\n",
      "start perkenalkan, ke 128\n",
      "start perkenalkan, ke 129\n",
      "start perkenalkan, ke 130\n",
      "start perkenalkan, ke 131\n",
      "start perkenalkan, ke 132\n",
      "start perkenalkan, ke 133\n",
      "start perkenalkan, ke 134\n",
      "start perkenalkan, ke 135\n",
      "start perkenalkan, ke 136\n",
      "start perkenalkan, ke 137\n",
      "start perkenalkan, ke 138\n",
      "start perkenalkan, ke 139\n",
      "start perkenalkan, ke 140\n",
      "start perkenalkan, ke 141\n",
      "start perkenalkan, ke 142\n",
      "start perkenalkan, ke 143\n",
      "start perkenalkan, ke 144\n",
      "start perkenalkan, ke 145\n",
      "start perkenalkan, ke 146\n",
      "start perkenalkan, ke 147\n",
      "start perkenalkan, ke 148\n",
      "start perkenalkan, ke 149\n",
      "start perkenalkan, ke 150\n",
      "start r, ke 1\n",
      "start r, ke 2\n",
      "start r, ke 3\n",
      "start r, ke 4\n",
      "start r, ke 5\n",
      "start r, ke 6\n",
      "start r, ke 7\n",
      "start r, ke 8\n",
      "start r, ke 9\n",
      "start r, ke 10\n",
      "start r, ke 11\n",
      "start r, ke 12\n",
      "start r, ke 13\n",
      "start r, ke 14\n",
      "start r, ke 15\n",
      "start r, ke 16\n",
      "start r, ke 17\n",
      "start r, ke 18\n",
      "start r, ke 19\n",
      "start r, ke 20\n",
      "start r, ke 21\n",
      "start r, ke 22\n",
      "start r, ke 23\n",
      "start r, ke 24\n",
      "start r, ke 25\n",
      "start r, ke 26\n",
      "start r, ke 27\n",
      "start r, ke 28\n",
      "start r, ke 29\n",
      "start r, ke 30\n",
      "start r, ke 31\n",
      "start r, ke 32\n",
      "start r, ke 33\n",
      "start r, ke 34\n",
      "start r, ke 35\n",
      "start r, ke 36\n",
      "start r, ke 37\n",
      "start r, ke 38\n",
      "start r, ke 39\n",
      "start r, ke 40\n",
      "start r, ke 41\n",
      "start r, ke 42\n",
      "start r, ke 43\n",
      "start r, ke 44\n",
      "start r, ke 45\n",
      "start r, ke 46\n",
      "start r, ke 47\n",
      "start r, ke 48\n",
      "start r, ke 49\n",
      "start r, ke 50\n",
      "start r, ke 51\n",
      "start r, ke 52\n",
      "start r, ke 53\n",
      "start r, ke 54\n",
      "start r, ke 55\n",
      "start r, ke 56\n",
      "start r, ke 57\n",
      "start r, ke 58\n",
      "start r, ke 59\n",
      "start r, ke 60\n",
      "start r, ke 61\n",
      "start r, ke 62\n",
      "start r, ke 63\n",
      "start r, ke 64\n",
      "start r, ke 65\n",
      "start r, ke 66\n",
      "start r, ke 67\n",
      "start r, ke 68\n",
      "start r, ke 69\n",
      "start r, ke 70\n",
      "start r, ke 71\n",
      "start r, ke 72\n",
      "start r, ke 73\n",
      "start r, ke 74\n",
      "start r, ke 75\n",
      "start r, ke 76\n",
      "start r, ke 77\n",
      "start r, ke 78\n",
      "start r, ke 79\n",
      "start r, ke 80\n",
      "start r, ke 81\n",
      "start r, ke 82\n",
      "start r, ke 83\n",
      "start r, ke 84\n",
      "start r, ke 85\n",
      "start r, ke 86\n",
      "start r, ke 87\n",
      "start r, ke 88\n",
      "start r, ke 89\n",
      "start r, ke 90\n",
      "start r, ke 91\n",
      "start r, ke 92\n",
      "start r, ke 93\n",
      "start r, ke 94\n",
      "start r, ke 95\n",
      "start r, ke 96\n",
      "start r, ke 97\n",
      "start r, ke 98\n",
      "start r, ke 99\n",
      "start r, ke 100\n",
      "start r, ke 101\n",
      "start r, ke 102\n",
      "start r, ke 103\n",
      "start r, ke 104\n",
      "start r, ke 105\n",
      "start r, ke 106\n",
      "start r, ke 107\n",
      "start r, ke 108\n",
      "start r, ke 109\n",
      "start r, ke 110\n",
      "start r, ke 111\n",
      "start r, ke 112\n",
      "start r, ke 113\n",
      "start r, ke 114\n",
      "start r, ke 115\n",
      "start r, ke 116\n",
      "start r, ke 117\n",
      "start r, ke 118\n",
      "start r, ke 119\n",
      "start r, ke 120\n",
      "start r, ke 121\n",
      "start r, ke 122\n",
      "start r, ke 123\n",
      "start r, ke 124\n",
      "start r, ke 125\n",
      "start r, ke 126\n",
      "start r, ke 127\n",
      "start r, ke 128\n",
      "start r, ke 129\n",
      "start r, ke 130\n",
      "start r, ke 131\n",
      "start r, ke 132\n",
      "start r, ke 133\n",
      "start r, ke 134\n",
      "start r, ke 135\n",
      "start r, ke 136\n",
      "start r, ke 137\n",
      "start r, ke 138\n",
      "start r, ke 139\n",
      "start r, ke 140\n",
      "start r, ke 141\n",
      "start r, ke 142\n",
      "start r, ke 143\n",
      "start r, ke 144\n",
      "start r, ke 145\n",
      "start r, ke 146\n",
      "start r, ke 147\n",
      "start r, ke 148\n",
      "start r, ke 149\n",
      "start r, ke 150\n",
      "start kami, ke 1\n",
      "start kami, ke 2\n",
      "start kami, ke 3\n",
      "start kami, ke 4\n",
      "start kami, ke 5\n",
      "start kami, ke 6\n",
      "start kami, ke 7\n",
      "start kami, ke 8\n",
      "start kami, ke 9\n",
      "start kami, ke 10\n",
      "start kami, ke 11\n",
      "start kami, ke 12\n",
      "start kami, ke 13\n",
      "start kami, ke 14\n",
      "start kami, ke 15\n",
      "start kami, ke 16\n",
      "start kami, ke 17\n",
      "start kami, ke 18\n",
      "start kami, ke 19\n",
      "start kami, ke 20\n",
      "start kami, ke 21\n",
      "start kami, ke 22\n",
      "start kami, ke 23\n",
      "start kami, ke 24\n",
      "start kami, ke 25\n",
      "start kami, ke 26\n",
      "start kami, ke 27\n",
      "start kami, ke 28\n",
      "start kami, ke 29\n",
      "start kami, ke 30\n",
      "start kami, ke 31\n",
      "start kami, ke 32\n",
      "start kami, ke 33\n",
      "start kami, ke 34\n",
      "start kami, ke 35\n",
      "start kami, ke 36\n",
      "start kami, ke 37\n",
      "start kami, ke 38\n",
      "start kami, ke 39\n",
      "start kami, ke 40\n",
      "start kami, ke 41\n",
      "start kami, ke 42\n",
      "start kami, ke 43\n",
      "start kami, ke 44\n",
      "start kami, ke 45\n",
      "start kami, ke 46\n",
      "start kami, ke 47\n",
      "start kami, ke 48\n",
      "start kami, ke 49\n",
      "start kami, ke 50\n",
      "start kami, ke 51\n",
      "start kami, ke 52\n",
      "start kami, ke 53\n",
      "start kami, ke 54\n",
      "start kami, ke 55\n",
      "start kami, ke 56\n",
      "start kami, ke 57\n",
      "start kami, ke 58\n",
      "start kami, ke 59\n",
      "start kami, ke 60\n",
      "start kami, ke 61\n",
      "start kami, ke 62\n",
      "start kami, ke 63\n",
      "start kami, ke 64\n",
      "start kami, ke 65\n",
      "start kami, ke 66\n",
      "start kami, ke 67\n",
      "start kami, ke 68\n",
      "start kami, ke 69\n",
      "start kami, ke 70\n",
      "start kami, ke 71\n",
      "start kami, ke 72\n",
      "start kami, ke 73\n",
      "start kami, ke 74\n",
      "start kami, ke 75\n",
      "start kami, ke 76\n",
      "start kami, ke 77\n",
      "start kami, ke 78\n",
      "start kami, ke 79\n",
      "start kami, ke 80\n",
      "start kami, ke 81\n",
      "start kami, ke 82\n",
      "start kami, ke 83\n",
      "start kami, ke 84\n",
      "start kami, ke 85\n",
      "start kami, ke 86\n",
      "start kami, ke 87\n",
      "start kami, ke 88\n",
      "start kami, ke 89\n",
      "start kami, ke 90\n",
      "start kami, ke 91\n",
      "start kami, ke 92\n",
      "start kami, ke 93\n",
      "start kami, ke 94\n",
      "start kami, ke 95\n",
      "start kami, ke 96\n",
      "start kami, ke 97\n",
      "start kami, ke 98\n",
      "start kami, ke 99\n",
      "start kami, ke 100\n",
      "start kami, ke 101\n",
      "start kami, ke 102\n",
      "start kami, ke 103\n",
      "start kami, ke 104\n",
      "start kami, ke 105\n",
      "start kami, ke 106\n",
      "start kami, ke 107\n",
      "start kami, ke 108\n",
      "start kami, ke 109\n",
      "start kami, ke 110\n",
      "start kami, ke 111\n",
      "start kami, ke 112\n",
      "start kami, ke 113\n",
      "start kami, ke 114\n",
      "start kami, ke 115\n",
      "start kami, ke 116\n",
      "start kami, ke 117\n",
      "start kami, ke 118\n",
      "start kami, ke 119\n",
      "start kami, ke 120\n",
      "start kami, ke 121\n",
      "start kami, ke 122\n",
      "start kami, ke 123\n",
      "start kami, ke 124\n",
      "start kami, ke 125\n",
      "start kami, ke 126\n",
      "start kami, ke 127\n",
      "start kami, ke 128\n",
      "start kami, ke 129\n",
      "start kami, ke 130\n",
      "start kami, ke 131\n",
      "start kami, ke 132\n",
      "start kami, ke 133\n",
      "start kami, ke 134\n",
      "start kami, ke 135\n",
      "start kami, ke 136\n",
      "start kami, ke 137\n",
      "start kami, ke 138\n",
      "start kami, ke 139\n",
      "start kami, ke 140\n",
      "start kami, ke 141\n",
      "start kami, ke 142\n",
      "start kami, ke 143\n",
      "start kami, ke 144\n",
      "start kami, ke 145\n",
      "start kami, ke 146\n",
      "start kami, ke 147\n",
      "start kami, ke 148\n",
      "start kami, ke 149\n",
      "start kami, ke 150\n",
      "start d, ke 1\n",
      "start d, ke 2\n",
      "start d, ke 3\n",
      "start d, ke 4\n",
      "start d, ke 5\n",
      "start d, ke 6\n",
      "start d, ke 7\n",
      "start d, ke 8\n",
      "start d, ke 9\n",
      "start d, ke 10\n",
      "start d, ke 11\n",
      "start d, ke 12\n",
      "start d, ke 13\n",
      "start d, ke 14\n",
      "start d, ke 15\n",
      "start d, ke 16\n",
      "start d, ke 17\n",
      "start d, ke 18\n",
      "start d, ke 19\n",
      "start d, ke 20\n",
      "start d, ke 21\n",
      "start d, ke 22\n",
      "start d, ke 23\n",
      "start d, ke 24\n",
      "start d, ke 25\n",
      "start d, ke 26\n",
      "start d, ke 27\n",
      "start d, ke 28\n",
      "start d, ke 29\n",
      "start d, ke 30\n",
      "start d, ke 31\n",
      "start d, ke 32\n",
      "start d, ke 33\n",
      "start d, ke 34\n",
      "start d, ke 35\n",
      "start d, ke 36\n",
      "start d, ke 37\n",
      "start d, ke 38\n",
      "start d, ke 39\n",
      "start d, ke 40\n",
      "start d, ke 41\n",
      "start d, ke 42\n",
      "start d, ke 43\n",
      "start d, ke 44\n",
      "start d, ke 45\n",
      "start d, ke 46\n",
      "start d, ke 47\n",
      "start d, ke 48\n",
      "start d, ke 49\n",
      "start d, ke 50\n",
      "start d, ke 51\n",
      "start d, ke 52\n",
      "start d, ke 53\n",
      "start d, ke 54\n",
      "start d, ke 55\n",
      "start d, ke 56\n",
      "start d, ke 57\n",
      "start d, ke 58\n",
      "start d, ke 59\n",
      "start d, ke 60\n",
      "start d, ke 61\n",
      "start d, ke 62\n",
      "start d, ke 63\n",
      "start d, ke 64\n",
      "start d, ke 65\n",
      "start d, ke 66\n",
      "start d, ke 67\n",
      "start d, ke 68\n",
      "start d, ke 69\n",
      "start d, ke 70\n",
      "start d, ke 71\n",
      "start d, ke 72\n",
      "start d, ke 73\n",
      "start d, ke 74\n",
      "start d, ke 75\n",
      "start d, ke 76\n",
      "start d, ke 77\n",
      "start d, ke 78\n",
      "start d, ke 79\n",
      "start d, ke 80\n",
      "start d, ke 81\n",
      "start d, ke 82\n",
      "start d, ke 83\n",
      "start d, ke 84\n",
      "start d, ke 85\n",
      "start d, ke 86\n",
      "start d, ke 87\n",
      "start d, ke 88\n",
      "start d, ke 89\n",
      "start d, ke 90\n",
      "start d, ke 91\n",
      "start d, ke 92\n",
      "start d, ke 93\n",
      "start d, ke 94\n",
      "start d, ke 95\n",
      "start d, ke 96\n",
      "start d, ke 97\n",
      "start d, ke 98\n",
      "start d, ke 99\n",
      "start d, ke 100\n",
      "start d, ke 101\n",
      "start d, ke 102\n",
      "start d, ke 103\n",
      "start d, ke 104\n",
      "start d, ke 105\n",
      "start d, ke 106\n",
      "start d, ke 107\n",
      "start d, ke 108\n",
      "start d, ke 109\n",
      "start d, ke 110\n",
      "start d, ke 111\n",
      "start d, ke 112\n",
      "start d, ke 113\n",
      "start d, ke 114\n",
      "start d, ke 115\n",
      "start d, ke 116\n",
      "start d, ke 117\n",
      "start d, ke 118\n",
      "start d, ke 119\n",
      "start d, ke 120\n",
      "start d, ke 121\n",
      "start d, ke 122\n",
      "start d, ke 123\n",
      "start d, ke 124\n",
      "start d, ke 125\n",
      "start d, ke 126\n",
      "start d, ke 127\n",
      "start d, ke 128\n",
      "start d, ke 129\n",
      "start d, ke 130\n",
      "start d, ke 131\n",
      "start d, ke 132\n",
      "start d, ke 133\n",
      "start d, ke 134\n",
      "start d, ke 135\n",
      "start d, ke 136\n",
      "start d, ke 137\n",
      "start d, ke 138\n",
      "start d, ke 139\n",
      "start d, ke 140\n",
      "start d, ke 141\n",
      "start d, ke 142\n",
      "start d, ke 143\n",
      "start d, ke 144\n",
      "start d, ke 145\n",
      "start d, ke 146\n",
      "start d, ke 147\n",
      "start d, ke 148\n",
      "start d, ke 149\n",
      "start d, ke 150\n",
      "start a, ke 1\n",
      "start a, ke 2\n",
      "start a, ke 3\n",
      "start a, ke 4\n",
      "start a, ke 5\n",
      "start a, ke 6\n",
      "start a, ke 7\n",
      "start a, ke 8\n",
      "start a, ke 9\n",
      "start a, ke 10\n",
      "start a, ke 11\n",
      "start a, ke 12\n",
      "start a, ke 13\n",
      "start a, ke 14\n",
      "start a, ke 15\n",
      "start a, ke 16\n",
      "start a, ke 17\n",
      "start a, ke 18\n",
      "start a, ke 19\n",
      "start a, ke 20\n",
      "start a, ke 21\n",
      "start a, ke 22\n",
      "start a, ke 23\n",
      "start a, ke 24\n",
      "start a, ke 25\n",
      "start a, ke 26\n",
      "start a, ke 27\n",
      "start a, ke 28\n",
      "start a, ke 29\n",
      "start a, ke 30\n",
      "start a, ke 31\n",
      "start a, ke 32\n",
      "start a, ke 33\n",
      "start a, ke 34\n",
      "start a, ke 35\n",
      "start a, ke 36\n",
      "start a, ke 37\n",
      "start a, ke 38\n",
      "start a, ke 39\n",
      "start a, ke 40\n",
      "start a, ke 41\n",
      "start a, ke 42\n",
      "start a, ke 43\n",
      "start a, ke 44\n",
      "start a, ke 45\n",
      "start a, ke 46\n",
      "start a, ke 47\n",
      "start a, ke 48\n",
      "start a, ke 49\n",
      "start a, ke 50\n",
      "start a, ke 51\n",
      "start a, ke 52\n",
      "start a, ke 53\n",
      "start a, ke 54\n",
      "start a, ke 55\n",
      "start a, ke 56\n",
      "start a, ke 57\n",
      "start a, ke 58\n",
      "start a, ke 59\n",
      "start a, ke 60\n",
      "start a, ke 61\n",
      "start a, ke 62\n",
      "start a, ke 63\n",
      "start a, ke 64\n",
      "start a, ke 65\n",
      "start a, ke 66\n",
      "start a, ke 67\n",
      "start a, ke 68\n",
      "start a, ke 69\n",
      "start a, ke 70\n",
      "start a, ke 71\n",
      "start a, ke 72\n",
      "start a, ke 73\n",
      "start a, ke 74\n",
      "start a, ke 75\n",
      "start a, ke 76\n",
      "start a, ke 77\n",
      "start a, ke 78\n",
      "start a, ke 79\n",
      "start a, ke 80\n",
      "start a, ke 81\n",
      "start a, ke 82\n",
      "start a, ke 83\n",
      "start a, ke 84\n",
      "start a, ke 85\n",
      "start a, ke 86\n",
      "start a, ke 87\n",
      "start a, ke 88\n",
      "start a, ke 89\n",
      "start a, ke 90\n",
      "start a, ke 91\n",
      "start a, ke 92\n",
      "start a, ke 93\n",
      "start a, ke 94\n",
      "start a, ke 95\n",
      "start a, ke 96\n",
      "start a, ke 97\n",
      "start a, ke 98\n",
      "start a, ke 99\n",
      "start a, ke 100\n",
      "start a, ke 101\n",
      "start a, ke 102\n",
      "start a, ke 103\n",
      "start a, ke 104\n",
      "start a, ke 105\n",
      "start a, ke 106\n",
      "start a, ke 107\n",
      "start a, ke 108\n",
      "start a, ke 109\n",
      "start a, ke 110\n",
      "start a, ke 111\n",
      "start a, ke 112\n",
      "start a, ke 113\n",
      "start a, ke 114\n",
      "start a, ke 115\n",
      "start a, ke 116\n",
      "start a, ke 117\n",
      "start a, ke 118\n",
      "start a, ke 119\n",
      "start a, ke 120\n",
      "start a, ke 121\n",
      "start a, ke 122\n",
      "start a, ke 123\n",
      "start a, ke 124\n",
      "start a, ke 125\n",
      "start a, ke 126\n",
      "start a, ke 127\n",
      "start a, ke 128\n",
      "start a, ke 129\n",
      "start a, ke 130\n",
      "start a, ke 131\n",
      "start a, ke 132\n",
      "start a, ke 133\n",
      "start a, ke 134\n",
      "start a, ke 135\n",
      "start a, ke 136\n",
      "start a, ke 137\n",
      "start a, ke 138\n",
      "start a, ke 139\n",
      "start a, ke 140\n",
      "start a, ke 141\n",
      "start a, ke 142\n",
      "start a, ke 143\n",
      "start a, ke 144\n",
      "start a, ke 145\n",
      "start a, ke 146\n",
      "start a, ke 147\n",
      "start a, ke 148\n",
      "start a, ke 149\n",
      "start a, ke 150\n",
      "start n, ke 1\n",
      "start n, ke 2\n",
      "start n, ke 3\n",
      "start n, ke 4\n",
      "start n, ke 5\n",
      "start n, ke 6\n",
      "start n, ke 7\n",
      "start n, ke 8\n",
      "start n, ke 9\n",
      "start n, ke 10\n",
      "start n, ke 11\n",
      "start n, ke 12\n",
      "start n, ke 13\n",
      "start n, ke 14\n",
      "start n, ke 15\n",
      "start n, ke 16\n",
      "start n, ke 17\n",
      "start n, ke 18\n",
      "start n, ke 19\n",
      "start n, ke 20\n",
      "start n, ke 21\n",
      "start n, ke 22\n",
      "start n, ke 23\n",
      "start n, ke 24\n",
      "start n, ke 25\n",
      "start n, ke 26\n",
      "start n, ke 27\n",
      "start n, ke 28\n",
      "start n, ke 29\n",
      "start n, ke 30\n",
      "start n, ke 31\n",
      "start n, ke 32\n",
      "start n, ke 33\n",
      "start n, ke 34\n",
      "start n, ke 35\n",
      "start n, ke 36\n",
      "start n, ke 37\n",
      "start n, ke 38\n",
      "start n, ke 39\n",
      "start n, ke 40\n",
      "start n, ke 41\n",
      "start n, ke 42\n",
      "start n, ke 43\n",
      "start n, ke 44\n",
      "start n, ke 45\n",
      "start n, ke 46\n",
      "start n, ke 47\n",
      "start n, ke 48\n",
      "start n, ke 49\n",
      "start n, ke 50\n",
      "start n, ke 51\n",
      "start n, ke 52\n",
      "start n, ke 53\n",
      "start n, ke 54\n",
      "start n, ke 55\n",
      "start n, ke 56\n",
      "start n, ke 57\n",
      "start n, ke 58\n",
      "start n, ke 59\n",
      "start n, ke 60\n",
      "start n, ke 61\n",
      "start n, ke 62\n",
      "start n, ke 63\n",
      "start n, ke 64\n",
      "start n, ke 65\n",
      "start n, ke 66\n",
      "start n, ke 67\n",
      "start n, ke 68\n",
      "start n, ke 69\n",
      "start n, ke 70\n",
      "start n, ke 71\n",
      "start n, ke 72\n",
      "start n, ke 73\n",
      "start n, ke 74\n",
      "start n, ke 75\n",
      "start n, ke 76\n",
      "start n, ke 77\n",
      "start n, ke 78\n",
      "start n, ke 79\n",
      "start n, ke 80\n",
      "start n, ke 81\n",
      "start n, ke 82\n",
      "start n, ke 83\n",
      "start n, ke 84\n",
      "start n, ke 85\n",
      "start n, ke 86\n",
      "start n, ke 87\n",
      "start n, ke 88\n",
      "start n, ke 89\n",
      "start n, ke 90\n",
      "start n, ke 91\n",
      "start n, ke 92\n",
      "start n, ke 93\n",
      "start n, ke 94\n",
      "start n, ke 95\n",
      "start n, ke 96\n",
      "start n, ke 97\n",
      "start n, ke 98\n",
      "start n, ke 99\n",
      "start n, ke 100\n",
      "start n, ke 101\n",
      "start n, ke 102\n",
      "start n, ke 103\n",
      "start n, ke 104\n",
      "start n, ke 105\n",
      "start n, ke 106\n",
      "start n, ke 107\n",
      "start n, ke 108\n",
      "start n, ke 109\n",
      "start n, ke 110\n",
      "start n, ke 111\n",
      "start n, ke 112\n",
      "start n, ke 113\n",
      "start n, ke 114\n",
      "start n, ke 115\n",
      "start n, ke 116\n",
      "start n, ke 117\n",
      "start n, ke 118\n",
      "start n, ke 119\n",
      "start n, ke 120\n",
      "start n, ke 121\n",
      "start n, ke 122\n",
      "start n, ke 123\n",
      "start n, ke 124\n",
      "start n, ke 125\n",
      "start n, ke 126\n",
      "start n, ke 127\n",
      "start n, ke 128\n",
      "start n, ke 129\n",
      "start n, ke 130\n",
      "start n, ke 131\n",
      "start n, ke 132\n",
      "start n, ke 133\n",
      "start n, ke 134\n",
      "start n, ke 135\n",
      "start n, ke 136\n",
      "start n, ke 137\n",
      "start n, ke 138\n",
      "start n, ke 139\n",
      "start n, ke 140\n",
      "start n, ke 141\n",
      "start n, ke 142\n",
      "start n, ke 143\n",
      "start n, ke 144\n",
      "start n, ke 145\n",
      "start n, ke 146\n",
      "start n, ke 147\n",
      "start n, ke 148\n",
      "start n, ke 149\n",
      "start n, ke 150\n",
      "start i, ke 1\n",
      "start i, ke 2\n",
      "start i, ke 3\n",
      "start i, ke 4\n",
      "start i, ke 5\n",
      "start i, ke 6\n",
      "start i, ke 7\n",
      "start i, ke 8\n",
      "start i, ke 9\n",
      "start i, ke 10\n",
      "start i, ke 11\n",
      "start i, ke 12\n",
      "start i, ke 13\n",
      "start i, ke 14\n",
      "start i, ke 15\n",
      "start i, ke 16\n",
      "start i, ke 17\n",
      "start i, ke 18\n",
      "start i, ke 19\n",
      "start i, ke 20\n",
      "start i, ke 21\n",
      "start i, ke 22\n",
      "start i, ke 23\n",
      "start i, ke 24\n",
      "start i, ke 25\n",
      "start i, ke 26\n",
      "start i, ke 27\n",
      "start i, ke 28\n",
      "start i, ke 29\n",
      "start i, ke 30\n",
      "start i, ke 31\n",
      "start i, ke 32\n",
      "start i, ke 33\n",
      "start i, ke 34\n",
      "start i, ke 35\n",
      "start i, ke 36\n",
      "start i, ke 37\n",
      "start i, ke 38\n",
      "start i, ke 39\n",
      "start i, ke 40\n",
      "start i, ke 41\n",
      "start i, ke 42\n",
      "start i, ke 43\n",
      "start i, ke 44\n",
      "start i, ke 45\n",
      "start i, ke 46\n",
      "start i, ke 47\n",
      "start i, ke 48\n",
      "start i, ke 49\n",
      "start i, ke 50\n",
      "start i, ke 51\n",
      "start i, ke 52\n",
      "start i, ke 53\n",
      "start i, ke 54\n",
      "start i, ke 55\n",
      "start i, ke 56\n",
      "start i, ke 57\n",
      "start i, ke 58\n",
      "start i, ke 59\n",
      "start i, ke 60\n",
      "start i, ke 61\n",
      "start i, ke 62\n",
      "start i, ke 63\n",
      "start i, ke 64\n",
      "start i, ke 65\n",
      "start i, ke 66\n",
      "start i, ke 67\n",
      "start i, ke 68\n",
      "start i, ke 69\n",
      "start i, ke 70\n",
      "start i, ke 71\n",
      "start i, ke 72\n",
      "start i, ke 73\n",
      "start i, ke 74\n",
      "start i, ke 75\n",
      "start i, ke 76\n",
      "start i, ke 77\n",
      "start i, ke 78\n",
      "start i, ke 79\n",
      "start i, ke 80\n",
      "start i, ke 81\n",
      "start i, ke 82\n",
      "start i, ke 83\n",
      "start i, ke 84\n",
      "start i, ke 85\n",
      "start i, ke 86\n",
      "start i, ke 87\n",
      "start i, ke 88\n",
      "start i, ke 89\n",
      "start i, ke 90\n",
      "start i, ke 91\n",
      "start i, ke 92\n",
      "start i, ke 93\n",
      "start i, ke 94\n",
      "start i, ke 95\n",
      "start i, ke 96\n",
      "start i, ke 97\n",
      "start i, ke 98\n",
      "start i, ke 99\n",
      "start i, ke 100\n",
      "start i, ke 101\n",
      "start i, ke 102\n",
      "start i, ke 103\n",
      "start i, ke 104\n",
      "start i, ke 105\n",
      "start i, ke 106\n",
      "start i, ke 107\n",
      "start i, ke 108\n",
      "start i, ke 109\n",
      "start i, ke 110\n",
      "start i, ke 111\n",
      "start i, ke 112\n",
      "start i, ke 113\n",
      "start i, ke 114\n",
      "start i, ke 115\n",
      "start i, ke 116\n",
      "start i, ke 117\n",
      "start i, ke 118\n",
      "start i, ke 119\n",
      "start i, ke 120\n",
      "start i, ke 121\n",
      "start i, ke 122\n",
      "start i, ke 123\n",
      "start i, ke 124\n",
      "start i, ke 125\n",
      "start i, ke 126\n",
      "start i, ke 127\n",
      "start i, ke 128\n",
      "start i, ke 129\n",
      "start i, ke 130\n",
      "start i, ke 131\n",
      "start i, ke 132\n",
      "start i, ke 133\n",
      "start i, ke 134\n",
      "start i, ke 135\n",
      "start i, ke 136\n",
      "start i, ke 137\n",
      "start i, ke 138\n",
      "start i, ke 139\n",
      "start i, ke 140\n",
      "start i, ke 141\n",
      "start i, ke 142\n",
      "start i, ke 143\n",
      "start i, ke 144\n",
      "start i, ke 145\n",
      "start i, ke 146\n",
      "start i, ke 147\n",
      "start i, ke 148\n",
      "start i, ke 149\n",
      "start i, ke 150\n",
      "start y, ke 1\n",
      "start y, ke 2\n",
      "start y, ke 3\n",
      "start y, ke 4\n",
      "start y, ke 5\n",
      "start y, ke 6\n",
      "start y, ke 7\n",
      "start y, ke 8\n",
      "start y, ke 9\n",
      "start y, ke 10\n",
      "start y, ke 11\n",
      "start y, ke 12\n",
      "start y, ke 13\n",
      "start y, ke 14\n",
      "start y, ke 15\n",
      "start y, ke 16\n",
      "start y, ke 17\n",
      "start y, ke 18\n",
      "start y, ke 19\n",
      "start y, ke 20\n",
      "start y, ke 21\n",
      "start y, ke 22\n",
      "start y, ke 23\n",
      "start y, ke 24\n",
      "start y, ke 25\n",
      "start y, ke 26\n",
      "start y, ke 27\n",
      "start y, ke 28\n",
      "start y, ke 29\n",
      "start y, ke 30\n",
      "start y, ke 31\n",
      "start y, ke 32\n",
      "start y, ke 33\n",
      "start y, ke 34\n",
      "start y, ke 35\n",
      "start y, ke 36\n",
      "start y, ke 37\n",
      "start y, ke 38\n",
      "start y, ke 39\n",
      "start y, ke 40\n",
      "start y, ke 41\n",
      "start y, ke 42\n",
      "start y, ke 43\n",
      "start y, ke 44\n",
      "start y, ke 45\n",
      "start y, ke 46\n",
      "start y, ke 47\n",
      "start y, ke 48\n",
      "start y, ke 49\n",
      "start y, ke 50\n",
      "start y, ke 51\n",
      "start y, ke 52\n",
      "start y, ke 53\n",
      "start y, ke 54\n",
      "start y, ke 55\n",
      "start y, ke 56\n",
      "start y, ke 57\n",
      "start y, ke 58\n",
      "start y, ke 59\n",
      "start y, ke 60\n",
      "start y, ke 61\n",
      "start y, ke 62\n",
      "start y, ke 63\n",
      "start y, ke 64\n",
      "start y, ke 65\n",
      "start y, ke 66\n",
      "start y, ke 67\n",
      "start y, ke 68\n",
      "start y, ke 69\n",
      "start y, ke 70\n",
      "start y, ke 71\n",
      "start y, ke 72\n",
      "start y, ke 73\n",
      "start y, ke 74\n",
      "start y, ke 75\n",
      "start y, ke 76\n",
      "start y, ke 77\n",
      "start y, ke 78\n",
      "start y, ke 79\n",
      "start y, ke 80\n",
      "start y, ke 81\n",
      "start y, ke 82\n",
      "start y, ke 83\n",
      "start y, ke 84\n",
      "start y, ke 85\n",
      "start y, ke 86\n",
      "start y, ke 87\n",
      "start y, ke 88\n",
      "start y, ke 89\n",
      "start y, ke 90\n",
      "start y, ke 91\n",
      "start y, ke 92\n",
      "start y, ke 93\n",
      "start y, ke 94\n",
      "start y, ke 95\n",
      "start y, ke 96\n",
      "start y, ke 97\n",
      "start y, ke 98\n",
      "start y, ke 99\n",
      "start y, ke 100\n",
      "start y, ke 101\n",
      "start y, ke 102\n",
      "start y, ke 103\n",
      "start y, ke 104\n",
      "start y, ke 105\n",
      "start y, ke 106\n",
      "start y, ke 107\n",
      "start y, ke 108\n",
      "start y, ke 109\n",
      "start y, ke 110\n",
      "start y, ke 111\n",
      "start y, ke 112\n",
      "start y, ke 113\n",
      "start y, ke 114\n",
      "start y, ke 115\n",
      "start y, ke 116\n",
      "start y, ke 117\n",
      "start y, ke 118\n",
      "start y, ke 119\n",
      "start y, ke 120\n",
      "start y, ke 121\n",
      "start y, ke 122\n",
      "start y, ke 123\n",
      "start y, ke 124\n",
      "start y, ke 125\n",
      "start y, ke 126\n",
      "start y, ke 127\n",
      "start y, ke 128\n",
      "start y, ke 129\n",
      "start y, ke 130\n",
      "start y, ke 131\n",
      "start y, ke 132\n",
      "start y, ke 133\n",
      "start y, ke 134\n",
      "start y, ke 135\n",
      "start y, ke 136\n",
      "start y, ke 137\n",
      "start y, ke 138\n",
      "start y, ke 139\n",
      "start y, ke 140\n",
      "start y, ke 141\n",
      "start y, ke 142\n",
      "start y, ke 143\n",
      "start y, ke 144\n",
      "start y, ke 145\n",
      "start y, ke 146\n",
      "start y, ke 147\n",
      "start y, ke 148\n",
      "start y, ke 149\n",
      "start y, ke 150\n",
      "start l, ke 1\n",
      "start l, ke 2\n",
      "start l, ke 3\n",
      "start l, ke 4\n",
      "start l, ke 5\n",
      "start l, ke 6\n",
      "start l, ke 7\n",
      "start l, ke 8\n",
      "start l, ke 9\n",
      "start l, ke 10\n",
      "start l, ke 11\n",
      "start l, ke 12\n",
      "start l, ke 13\n",
      "start l, ke 14\n",
      "start l, ke 15\n",
      "start l, ke 16\n",
      "start l, ke 17\n",
      "start l, ke 18\n",
      "start l, ke 19\n",
      "start l, ke 20\n",
      "start l, ke 21\n",
      "start l, ke 22\n",
      "start l, ke 23\n",
      "start l, ke 24\n",
      "start l, ke 25\n",
      "start l, ke 26\n",
      "start l, ke 27\n",
      "start l, ke 28\n",
      "start l, ke 29\n",
      "start l, ke 30\n",
      "start l, ke 31\n",
      "start l, ke 32\n",
      "start l, ke 33\n",
      "start l, ke 34\n",
      "start l, ke 35\n",
      "start l, ke 36\n",
      "start l, ke 37\n",
      "start l, ke 38\n",
      "start l, ke 39\n",
      "start l, ke 40\n",
      "start l, ke 41\n",
      "start l, ke 42\n",
      "start l, ke 43\n",
      "start l, ke 44\n",
      "start l, ke 45\n",
      "start l, ke 46\n",
      "start l, ke 47\n",
      "start l, ke 48\n",
      "start l, ke 49\n",
      "start l, ke 50\n",
      "start l, ke 51\n",
      "start l, ke 52\n",
      "start l, ke 53\n",
      "start l, ke 54\n",
      "start l, ke 55\n",
      "start l, ke 56\n",
      "start l, ke 57\n",
      "start l, ke 58\n",
      "start l, ke 59\n",
      "start l, ke 60\n",
      "start l, ke 61\n",
      "start l, ke 62\n",
      "start l, ke 63\n",
      "start l, ke 64\n",
      "start l, ke 65\n",
      "start l, ke 66\n",
      "start l, ke 67\n",
      "start l, ke 68\n",
      "start l, ke 69\n",
      "start l, ke 70\n",
      "start l, ke 71\n",
      "start l, ke 72\n",
      "start l, ke 73\n",
      "start l, ke 74\n",
      "start l, ke 75\n",
      "start l, ke 76\n",
      "start l, ke 77\n",
      "start l, ke 78\n",
      "start l, ke 79\n",
      "start l, ke 80\n",
      "start l, ke 81\n",
      "start l, ke 82\n",
      "start l, ke 83\n",
      "start l, ke 84\n",
      "start l, ke 85\n",
      "start l, ke 86\n",
      "start l, ke 87\n",
      "start l, ke 88\n",
      "start l, ke 89\n",
      "start l, ke 90\n",
      "start l, ke 91\n",
      "start l, ke 92\n",
      "start l, ke 93\n",
      "start l, ke 94\n",
      "start l, ke 95\n",
      "start l, ke 96\n",
      "start l, ke 97\n",
      "start l, ke 98\n",
      "start l, ke 99\n",
      "start l, ke 100\n",
      "start l, ke 101\n",
      "start l, ke 102\n",
      "start l, ke 103\n",
      "start l, ke 104\n",
      "start l, ke 105\n",
      "start l, ke 106\n",
      "start l, ke 107\n",
      "start l, ke 108\n",
      "start l, ke 109\n",
      "start l, ke 110\n",
      "start l, ke 111\n",
      "start l, ke 112\n",
      "start l, ke 113\n",
      "start l, ke 114\n",
      "start l, ke 115\n",
      "start l, ke 116\n",
      "start l, ke 117\n",
      "start l, ke 118\n",
      "start l, ke 119\n",
      "start l, ke 120\n",
      "start l, ke 121\n",
      "start l, ke 122\n",
      "start l, ke 123\n",
      "start l, ke 124\n",
      "start l, ke 125\n",
      "start l, ke 126\n",
      "start l, ke 127\n",
      "start l, ke 128\n",
      "start l, ke 129\n",
      "start l, ke 130\n",
      "start l, ke 131\n",
      "start l, ke 132\n",
      "start l, ke 133\n",
      "start l, ke 134\n",
      "start l, ke 135\n",
      "start l, ke 136\n",
      "start l, ke 137\n",
      "start l, ke 138\n",
      "start l, ke 139\n",
      "start l, ke 140\n",
      "start l, ke 141\n",
      "start l, ke 142\n",
      "start l, ke 143\n",
      "start l, ke 144\n",
      "start l, ke 145\n",
      "start l, ke 146\n",
      "start l, ke 147\n",
      "start l, ke 148\n",
      "start l, ke 149\n",
      "start l, ke 150\n",
      "start u, ke 1\n",
      "start u, ke 2\n",
      "start u, ke 3\n",
      "start u, ke 4\n",
      "start u, ke 5\n",
      "start u, ke 6\n",
      "start u, ke 7\n",
      "start u, ke 8\n",
      "start u, ke 9\n",
      "start u, ke 10\n",
      "start u, ke 11\n",
      "start u, ke 12\n",
      "start u, ke 13\n",
      "start u, ke 14\n",
      "start u, ke 15\n",
      "start u, ke 16\n",
      "start u, ke 17\n",
      "start u, ke 18\n",
      "start u, ke 19\n",
      "start u, ke 20\n",
      "start u, ke 21\n",
      "start u, ke 22\n",
      "start u, ke 23\n",
      "start u, ke 24\n",
      "start u, ke 25\n",
      "start u, ke 26\n",
      "start u, ke 27\n",
      "start u, ke 28\n",
      "start u, ke 29\n",
      "start u, ke 30\n",
      "start u, ke 31\n",
      "start u, ke 32\n",
      "start u, ke 33\n",
      "start u, ke 34\n",
      "start u, ke 35\n",
      "start u, ke 36\n",
      "start u, ke 37\n",
      "start u, ke 38\n",
      "start u, ke 39\n",
      "start u, ke 40\n",
      "start u, ke 41\n",
      "start u, ke 42\n",
      "start u, ke 43\n",
      "start u, ke 44\n",
      "start u, ke 45\n",
      "start u, ke 46\n",
      "start u, ke 47\n",
      "start u, ke 48\n",
      "start u, ke 49\n",
      "start u, ke 50\n",
      "start u, ke 51\n",
      "start u, ke 52\n",
      "start u, ke 53\n",
      "start u, ke 54\n",
      "start u, ke 55\n",
      "start u, ke 56\n",
      "start u, ke 57\n",
      "start u, ke 58\n",
      "start u, ke 59\n",
      "start u, ke 60\n",
      "start u, ke 61\n",
      "start u, ke 62\n",
      "start u, ke 63\n",
      "start u, ke 64\n",
      "start u, ke 65\n",
      "start u, ke 66\n",
      "start u, ke 67\n",
      "start u, ke 68\n",
      "start u, ke 69\n",
      "start u, ke 70\n",
      "start u, ke 71\n",
      "start u, ke 72\n",
      "start u, ke 73\n",
      "start u, ke 74\n",
      "start u, ke 75\n",
      "start u, ke 76\n",
      "start u, ke 77\n",
      "start u, ke 78\n",
      "start u, ke 79\n",
      "start u, ke 80\n",
      "start u, ke 81\n",
      "start u, ke 82\n",
      "start u, ke 83\n",
      "start u, ke 84\n",
      "start u, ke 85\n",
      "start u, ke 86\n",
      "start u, ke 87\n",
      "start u, ke 88\n",
      "start u, ke 89\n",
      "start u, ke 90\n",
      "start u, ke 91\n",
      "start u, ke 92\n",
      "start u, ke 93\n",
      "start u, ke 94\n",
      "start u, ke 95\n",
      "start u, ke 96\n",
      "start u, ke 97\n",
      "start u, ke 98\n",
      "start u, ke 99\n",
      "start u, ke 100\n",
      "start u, ke 101\n",
      "start u, ke 102\n",
      "start u, ke 103\n",
      "start u, ke 104\n",
      "start u, ke 105\n",
      "start u, ke 106\n",
      "start u, ke 107\n",
      "start u, ke 108\n",
      "start u, ke 109\n",
      "start u, ke 110\n",
      "start u, ke 111\n",
      "start u, ke 112\n",
      "start u, ke 113\n",
      "start u, ke 114\n",
      "start u, ke 115\n",
      "start u, ke 116\n",
      "start u, ke 117\n",
      "start u, ke 118\n",
      "start u, ke 119\n",
      "start u, ke 120\n",
      "start u, ke 121\n",
      "start u, ke 122\n",
      "start u, ke 123\n",
      "start u, ke 124\n",
      "start u, ke 125\n",
      "start u, ke 126\n",
      "start u, ke 127\n",
      "start u, ke 128\n",
      "start u, ke 129\n",
      "start u, ke 130\n",
      "start u, ke 131\n",
      "start u, ke 132\n",
      "start u, ke 133\n",
      "start u, ke 134\n",
      "start u, ke 135\n",
      "start u, ke 136\n",
      "start u, ke 137\n",
      "start u, ke 138\n",
      "start u, ke 139\n",
      "start u, ke 140\n",
      "start u, ke 141\n",
      "start u, ke 142\n",
      "start u, ke 143\n",
      "start u, ke 144\n",
      "start u, ke 145\n",
      "start u, ke 146\n",
      "start u, ke 147\n",
      "start u, ke 148\n",
      "start u, ke 149\n",
      "start u, ke 150\n",
      "start g, ke 1\n",
      "start g, ke 2\n",
      "start g, ke 3\n",
      "start g, ke 4\n",
      "start g, ke 5\n",
      "start g, ke 6\n",
      "start g, ke 7\n",
      "start g, ke 8\n",
      "start g, ke 9\n",
      "start g, ke 10\n",
      "start g, ke 11\n",
      "start g, ke 12\n",
      "start g, ke 13\n",
      "start g, ke 14\n",
      "start g, ke 15\n",
      "start g, ke 16\n",
      "start g, ke 17\n",
      "start g, ke 18\n",
      "start g, ke 19\n",
      "start g, ke 20\n",
      "start g, ke 21\n",
      "start g, ke 22\n",
      "start g, ke 23\n",
      "start g, ke 24\n",
      "start g, ke 25\n",
      "start g, ke 26\n",
      "start g, ke 27\n",
      "start g, ke 28\n",
      "start g, ke 29\n",
      "start g, ke 30\n",
      "start g, ke 31\n",
      "start g, ke 32\n",
      "start g, ke 33\n",
      "start g, ke 34\n",
      "start g, ke 35\n",
      "start g, ke 36\n",
      "start g, ke 37\n",
      "start g, ke 38\n",
      "start g, ke 39\n",
      "start g, ke 40\n",
      "start g, ke 41\n",
      "start g, ke 42\n",
      "start g, ke 43\n",
      "start g, ke 44\n",
      "start g, ke 45\n",
      "start g, ke 46\n",
      "start g, ke 47\n",
      "start g, ke 48\n",
      "start g, ke 49\n",
      "start g, ke 50\n",
      "start g, ke 51\n",
      "start g, ke 52\n",
      "start g, ke 53\n",
      "start g, ke 54\n",
      "start g, ke 55\n",
      "start g, ke 56\n",
      "start g, ke 57\n",
      "start g, ke 58\n",
      "start g, ke 59\n",
      "start g, ke 60\n",
      "start g, ke 61\n",
      "start g, ke 62\n",
      "start g, ke 63\n",
      "start g, ke 64\n",
      "start g, ke 65\n",
      "start g, ke 66\n",
      "start g, ke 67\n",
      "start g, ke 68\n",
      "start g, ke 69\n",
      "start g, ke 70\n",
      "start g, ke 71\n",
      "start g, ke 72\n",
      "start g, ke 73\n",
      "start g, ke 74\n",
      "start g, ke 75\n",
      "start g, ke 76\n",
      "start g, ke 77\n",
      "start g, ke 78\n",
      "start g, ke 79\n",
      "start g, ke 80\n",
      "start g, ke 81\n",
      "start g, ke 82\n",
      "start g, ke 83\n",
      "start g, ke 84\n",
      "start g, ke 85\n",
      "start g, ke 86\n",
      "start g, ke 87\n",
      "start g, ke 88\n",
      "start g, ke 89\n",
      "start g, ke 90\n",
      "start g, ke 91\n",
      "start g, ke 92\n",
      "start g, ke 93\n",
      "start g, ke 94\n",
      "start g, ke 95\n",
      "start g, ke 96\n",
      "start g, ke 97\n",
      "start g, ke 98\n",
      "start g, ke 99\n",
      "start g, ke 100\n",
      "start g, ke 101\n",
      "start g, ke 102\n",
      "start g, ke 103\n",
      "start g, ke 104\n",
      "start g, ke 105\n",
      "start g, ke 106\n",
      "start g, ke 107\n",
      "start g, ke 108\n",
      "start g, ke 109\n",
      "start g, ke 110\n",
      "start g, ke 111\n",
      "start g, ke 112\n",
      "start g, ke 113\n",
      "start g, ke 114\n",
      "start g, ke 115\n",
      "start g, ke 116\n",
      "start g, ke 117\n",
      "start g, ke 118\n",
      "start g, ke 119\n",
      "start g, ke 120\n",
      "start g, ke 121\n",
      "start g, ke 122\n",
      "start g, ke 123\n",
      "start g, ke 124\n",
      "start g, ke 125\n",
      "start g, ke 126\n",
      "start g, ke 127\n",
      "start g, ke 128\n",
      "start g, ke 129\n",
      "start g, ke 130\n",
      "start g, ke 131\n",
      "start g, ke 132\n",
      "start g, ke 133\n",
      "start g, ke 134\n",
      "start g, ke 135\n",
      "start g, ke 136\n",
      "start g, ke 137\n",
      "start g, ke 138\n",
      "start g, ke 139\n",
      "start g, ke 140\n",
      "start g, ke 141\n",
      "start g, ke 142\n",
      "start g, ke 143\n",
      "start g, ke 144\n",
      "start g, ke 145\n",
      "start g, ke 146\n",
      "start g, ke 147\n",
      "start g, ke 148\n",
      "start g, ke 149\n",
      "start g, ke 150\n",
      "start m, ke 1\n",
      "start m, ke 2\n",
      "start m, ke 3\n",
      "start m, ke 4\n",
      "start m, ke 5\n",
      "start m, ke 6\n",
      "start m, ke 7\n",
      "start m, ke 8\n",
      "start m, ke 9\n",
      "start m, ke 10\n",
      "start m, ke 11\n",
      "start m, ke 12\n",
      "start m, ke 13\n",
      "start m, ke 14\n",
      "start m, ke 15\n",
      "start m, ke 16\n",
      "start m, ke 17\n",
      "start m, ke 18\n",
      "start m, ke 19\n",
      "start m, ke 20\n",
      "start m, ke 21\n",
      "start m, ke 22\n",
      "start m, ke 23\n",
      "start m, ke 24\n",
      "start m, ke 25\n",
      "start m, ke 26\n",
      "start m, ke 27\n",
      "start m, ke 28\n",
      "start m, ke 29\n",
      "start m, ke 30\n",
      "start m, ke 31\n",
      "start m, ke 32\n",
      "start m, ke 33\n",
      "start m, ke 34\n",
      "start m, ke 35\n",
      "start m, ke 36\n",
      "start m, ke 37\n",
      "start m, ke 38\n",
      "start m, ke 39\n",
      "start m, ke 40\n",
      "start m, ke 41\n",
      "start m, ke 42\n",
      "start m, ke 43\n",
      "start m, ke 44\n",
      "start m, ke 45\n",
      "start m, ke 46\n",
      "start m, ke 47\n",
      "start m, ke 48\n",
      "start m, ke 49\n",
      "start m, ke 50\n",
      "start m, ke 51\n",
      "start m, ke 52\n",
      "start m, ke 53\n",
      "start m, ke 54\n",
      "start m, ke 55\n",
      "start m, ke 56\n",
      "start m, ke 57\n",
      "start m, ke 58\n",
      "start m, ke 59\n",
      "start m, ke 60\n",
      "start m, ke 61\n",
      "start m, ke 62\n",
      "start m, ke 63\n",
      "start m, ke 64\n",
      "start m, ke 65\n",
      "start m, ke 66\n",
      "start m, ke 67\n",
      "start m, ke 68\n",
      "start m, ke 69\n",
      "start m, ke 70\n",
      "start m, ke 71\n",
      "start m, ke 72\n",
      "start m, ke 73\n",
      "start m, ke 74\n",
      "start m, ke 75\n",
      "start m, ke 76\n",
      "start m, ke 77\n",
      "start m, ke 78\n",
      "start m, ke 79\n",
      "start m, ke 80\n",
      "start m, ke 81\n",
      "start m, ke 82\n",
      "start m, ke 83\n",
      "start m, ke 84\n",
      "start m, ke 85\n",
      "start m, ke 86\n",
      "start m, ke 87\n",
      "start m, ke 88\n",
      "start m, ke 89\n",
      "start m, ke 90\n",
      "start m, ke 91\n",
      "start m, ke 92\n",
      "start m, ke 93\n",
      "start m, ke 94\n",
      "start m, ke 95\n",
      "start m, ke 96\n",
      "start m, ke 97\n",
      "start m, ke 98\n",
      "start m, ke 99\n",
      "start m, ke 100\n",
      "start m, ke 101\n",
      "start m, ke 102\n",
      "start m, ke 103\n",
      "start m, ke 104\n",
      "start m, ke 105\n",
      "start m, ke 106\n",
      "start m, ke 107\n",
      "start m, ke 108\n",
      "start m, ke 109\n",
      "start m, ke 110\n",
      "start m, ke 111\n",
      "start m, ke 112\n",
      "start m, ke 113\n",
      "start m, ke 114\n",
      "start m, ke 115\n",
      "start m, ke 116\n",
      "start m, ke 117\n",
      "start m, ke 118\n",
      "start m, ke 119\n",
      "start m, ke 120\n",
      "start m, ke 121\n",
      "start m, ke 122\n",
      "start m, ke 123\n",
      "start m, ke 124\n",
      "start m, ke 125\n",
      "start m, ke 126\n",
      "start m, ke 127\n",
      "start m, ke 128\n",
      "start m, ke 129\n",
      "start m, ke 130\n",
      "start m, ke 131\n",
      "start m, ke 132\n",
      "start m, ke 133\n",
      "start m, ke 134\n",
      "start m, ke 135\n",
      "start m, ke 136\n",
      "start m, ke 137\n",
      "start m, ke 138\n",
      "start m, ke 139\n",
      "start m, ke 140\n",
      "start m, ke 141\n",
      "start m, ke 142\n",
      "start m, ke 143\n",
      "start m, ke 144\n",
      "start m, ke 145\n",
      "start m, ke 146\n",
      "start m, ke 147\n",
      "start m, ke 148\n",
      "start m, ke 149\n",
      "start m, ke 150\n"
     ]
    }
   ],
   "source": [
    "sq = 0\n",
    "sequence_length = 10\n",
    "for i in range(15):\n",
    "    # sequence_length = 32\n",
    "    \n",
    "    for sequence in range(150):\n",
    "        print('start {}, ke {}'.format(actions2[i], sequence+1))\n",
    "        cap = cv2.VideoCapture(\"F:/Work/2022/ifest-bisindo-translator/ml/dataset/{}/{}.mp4\".format(actions2[i], sequence))\n",
    "        sequence += sq\n",
    "        with mp_detect.mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "            for frame_num in range(sequence_length):\n",
    "                if frame_num > sequence_length-6:\n",
    "                    # Read feed\n",
    "                    ret, frame = cap.read()\n",
    "\n",
    "                    # Make detections\n",
    "                    image, results = mp_detect.mediapipe_detection(frame, holistic)\n",
    "\n",
    "                    # Draw landmarks\n",
    "                    # mp_detect.draw_styled_landmarks(image, results)\n",
    "                    \n",
    "                    keypoints = mp_detect.extract_keypoints_only_handpose(results)\n",
    "                    # \n",
    "                    npy_path = os.path.join(DATA_PATH, str('start'), str(sequence), str(frame_num-(sequence_length-7+2)))\n",
    "                    np.save(npy_path, keypoints)\n",
    "\n",
    "                # Break gracefully\n",
    "                if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                    break\n",
    "                        \n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "    sq+=150\n",
    "    # sequence_length+=6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start video ke 0\n",
      "start video ke 1\n",
      "start video ke 2\n",
      "last sequence = 2170\n"
     ]
    }
   ],
   "source": [
    "sq = 2095\n",
    "  \n",
    "for sequence in range(3):\n",
    "    print('start video ke {}'.format(sequence))\n",
    "    sequence_length = 5+4+2 \n",
    "    for i in range(25):\n",
    "        cap = cv2.VideoCapture(\"F:/Work/2022/ifest-bisindo-translator/ml/additional_nothing_dataset/{}.mp4\".format(sequence))\n",
    "        # sequence += sq\n",
    "        with mp_detect.mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "            for frame_num in range(sequence_length):\n",
    "                if frame_num > sequence_length-6:\n",
    "                    # Read feed\n",
    "                    ret, frame = cap.read()\n",
    "\n",
    "                    # Make detections\n",
    "                    image, results = mp_detect.mediapipe_detection(frame, holistic)\n",
    "\n",
    "                    # Draw landmarks\n",
    "                    # mp_detect.draw_styled_landmarks(image, results)\n",
    "                    \n",
    "                    keypoints = mp_detect.extract_keypoints_only_handpose(results)\n",
    "                    # \n",
    "                    npy_path = os.path.join(DATA_PATH, str('continue'), str(sq), str(frame_num-(sequence_length-7+2)))\n",
    "                    np.save(npy_path, keypoints)\n",
    "\n",
    "                # Break gracefully\n",
    "                if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                    break                \n",
    "            cap.release()\n",
    "            cv2.destroyAllWindows()\n",
    "        sq+=1\n",
    "        sequence_length+=7\n",
    "\n",
    "print(\"last sequence = {}\".format(sq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.52671254  0.23856722 -0.6998564  ...  0.          0.\n",
      "  0.        ]\n"
     ]
    }
   ],
   "source": [
    "print(keypoints)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Preprocess Data and Create Labels and Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = np.array(['start', 'continue'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {label:num for num, label in enumerate(actions)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'start': 0, 'continue': 1}"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = os.path.join('Dataset_Keypoints_start_record') \n",
    "sequences, labels = [], []\n",
    "for action in actions:\n",
    "    for sequence in range(2250):\n",
    "        window = []\n",
    "        for frame_num in range(4):\n",
    "            # res = np.load(\"F:/Work/2022/ifest-bisindo-translator/ml/Dataset_Keypoints_Data/{}/{}.npy\".format(action, frame_num))\n",
    "            res = np.load(os.path.join(DATA_PATH, action, str(sequence), \"{}.npy\".format(frame_num)))\n",
    "            window.append(res)\n",
    "        sequences.append(window)\n",
    "        labels.append(label_map[action])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4500, 4, 48)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(sequences).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4500,)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(labels).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4500, 4, 48)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = to_categorical(labels).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, X_test, y, y_test = train_test_split(X, y, test_size=0.2, shuffle=True)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.25, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(900, 2)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(900, 2)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "__dataname = ['X_test', 'y_test', 'X_train', 'X_val', 'y_train', 'y_val']\n",
    "__data = [X_test,y_test, X_train, X_val, y_train, y_val]\n",
    "\n",
    "for i in range(6):\n",
    "    with open('{}.txt'.format(__dataname[i]), 'w') as f:\n",
    "        f.write(__dataname[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_train2, y_train1, y_train2 = train_test_split(X_train, y_train, train_size=0.5, shuffle=True)\n",
    "x_train_ = [X_train1, X_train2]\n",
    "y_train_ = [y_train1, y_train2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = os.path.join('Dataset_Keypoints_Data_wo_face_sintetic') \n",
    "sequences2, labels2 = [], []\n",
    "for action in actions:\n",
    "    for sequence in np.array(os.listdir(os.path.join(DATA_PATH, action))).astype(int):\n",
    "        window = []\n",
    "        for frame_num in range(45):\n",
    "            # res = np.load(\"F:/Work/2022/ifest-bisindo-translator/ml/Dataset_Keypoints_Data/{}/{}.npy\".format(action, frame_num))\n",
    "            res = np.load(os.path.join(DATA_PATH, action, str(sequence), \"{}.npy\".format(frame_num)))\n",
    "            window.append(res)\n",
    "        sequences2.append(window)\n",
    "        labels2.append(label_map[action])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_2 = to_categorical(labels2).astype(int)\n",
    "X_train_2 = np.array(sequences2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Build and Train LSTM Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Flatten\n",
    "from tensorflow.keras.callbacks import TensorBoard, Callback\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "class trainingCallback(Callback):\n",
    "  def on_epoch_end(self, epoch, logs={}):\n",
    "    \n",
    "    # Check accuracy\n",
    "    # if(logs.get('categorical_accuracy') < 0.95  and logs.get('loss') < 0.35 and logs.get('val_loss') < 0.35):\n",
    "    if((logs.get('categorical_accuracy') > 0.98) or (logs.get('categorical_accuracy') > 0.97  and logs.get('loss') > logs.get('val_loss'))):\n",
    "      # Stop if threshold is met\n",
    "      print(\"\\nAccuracy grater than 0.95 so cancelling training!\")\n",
    "      self.model.stop_training = True\n",
    "\n",
    "# Instantiate class\n",
    "callbacks = trainingCallback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = os.path.join('Logs')\n",
    "tb_callback = TensorBoard(log_dir=log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(64, return_sequences=True, activation='relu', input_shape=(4,48)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(LSTM(128, return_sequences=True, activation='relu'))\n",
    "model.add(LSTM(64, return_sequences=True, activation='relu'))\n",
    "# model.add(LSTM(128, return_sequences=False, activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(actions.shape[0], activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=1e-3), loss='categorical_crossentropy', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "43/43 [==============================] - 9s 55ms/step - loss: 0.6669 - categorical_accuracy: 0.5589 - val_loss: 0.5702 - val_categorical_accuracy: 0.6811\n",
      "Epoch 2/1000\n",
      "43/43 [==============================] - 1s 35ms/step - loss: 0.5227 - categorical_accuracy: 0.7189 - val_loss: 0.4630 - val_categorical_accuracy: 0.7444\n",
      "Epoch 3/1000\n",
      "43/43 [==============================] - 1s 32ms/step - loss: 0.4596 - categorical_accuracy: 0.7659 - val_loss: 0.4407 - val_categorical_accuracy: 0.7822\n",
      "Epoch 4/1000\n",
      "43/43 [==============================] - 1s 31ms/step - loss: 0.4264 - categorical_accuracy: 0.7822 - val_loss: 0.3952 - val_categorical_accuracy: 0.7967\n",
      "Epoch 5/1000\n",
      "43/43 [==============================] - 1s 32ms/step - loss: 0.3840 - categorical_accuracy: 0.8063 - val_loss: 0.3680 - val_categorical_accuracy: 0.8100\n",
      "Epoch 6/1000\n",
      "43/43 [==============================] - 1s 32ms/step - loss: 0.3615 - categorical_accuracy: 0.8289 - val_loss: 0.3800 - val_categorical_accuracy: 0.8144\n",
      "Epoch 7/1000\n",
      "43/43 [==============================] - 1s 31ms/step - loss: 0.3289 - categorical_accuracy: 0.8511 - val_loss: 0.3244 - val_categorical_accuracy: 0.8533\n",
      "Epoch 8/1000\n",
      "43/43 [==============================] - 2s 37ms/step - loss: 0.2957 - categorical_accuracy: 0.8781 - val_loss: 0.3623 - val_categorical_accuracy: 0.8500\n",
      "Epoch 9/1000\n",
      "43/43 [==============================] - 1s 33ms/step - loss: 0.2945 - categorical_accuracy: 0.8748 - val_loss: 0.2769 - val_categorical_accuracy: 0.8789\n",
      "Epoch 10/1000\n",
      "43/43 [==============================] - 2s 36ms/step - loss: 0.2709 - categorical_accuracy: 0.8919 - val_loss: 0.2633 - val_categorical_accuracy: 0.8856\n",
      "Epoch 11/1000\n",
      "43/43 [==============================] - 1s 34ms/step - loss: 0.2511 - categorical_accuracy: 0.8941 - val_loss: 0.2771 - val_categorical_accuracy: 0.8689\n",
      "Epoch 12/1000\n",
      "43/43 [==============================] - 1s 32ms/step - loss: 0.2314 - categorical_accuracy: 0.9063 - val_loss: 0.2477 - val_categorical_accuracy: 0.8944\n",
      "Epoch 13/1000\n",
      "43/43 [==============================] - 1s 34ms/step - loss: 0.2299 - categorical_accuracy: 0.9070 - val_loss: 0.2370 - val_categorical_accuracy: 0.9056\n",
      "Epoch 14/1000\n",
      "43/43 [==============================] - 2s 35ms/step - loss: 0.2262 - categorical_accuracy: 0.9107 - val_loss: 0.2689 - val_categorical_accuracy: 0.8678\n",
      "Epoch 15/1000\n",
      "43/43 [==============================] - 1s 34ms/step - loss: 0.3341 - categorical_accuracy: 0.8374 - val_loss: 0.2863 - val_categorical_accuracy: 0.8711\n",
      "Epoch 16/1000\n",
      "43/43 [==============================] - 1s 33ms/step - loss: 0.2782 - categorical_accuracy: 0.8730 - val_loss: 0.2578 - val_categorical_accuracy: 0.8778\n",
      "Epoch 17/1000\n",
      "43/43 [==============================] - 1s 33ms/step - loss: 0.2448 - categorical_accuracy: 0.8959 - val_loss: 0.2250 - val_categorical_accuracy: 0.8978\n",
      "Epoch 18/1000\n",
      "43/43 [==============================] - 1s 32ms/step - loss: 0.2285 - categorical_accuracy: 0.9070 - val_loss: 0.2249 - val_categorical_accuracy: 0.9156\n",
      "Epoch 19/1000\n",
      "43/43 [==============================] - 2s 37ms/step - loss: 0.2090 - categorical_accuracy: 0.9148 - val_loss: 0.2068 - val_categorical_accuracy: 0.9144\n",
      "Epoch 20/1000\n",
      "43/43 [==============================] - 1s 31ms/step - loss: 0.2132 - categorical_accuracy: 0.9104 - val_loss: 0.2134 - val_categorical_accuracy: 0.9100\n",
      "Epoch 21/1000\n",
      "43/43 [==============================] - 2s 35ms/step - loss: 0.2118 - categorical_accuracy: 0.9152 - val_loss: 0.2515 - val_categorical_accuracy: 0.8622\n",
      "Epoch 22/1000\n",
      "43/43 [==============================] - 1s 34ms/step - loss: 0.2240 - categorical_accuracy: 0.9070 - val_loss: 0.2153 - val_categorical_accuracy: 0.9044\n",
      "Epoch 23/1000\n",
      "43/43 [==============================] - 1s 32ms/step - loss: 0.1992 - categorical_accuracy: 0.9244 - val_loss: 0.2779 - val_categorical_accuracy: 0.8622\n",
      "Epoch 24/1000\n",
      "43/43 [==============================] - 1s 34ms/step - loss: 0.1981 - categorical_accuracy: 0.9233 - val_loss: 0.2189 - val_categorical_accuracy: 0.8978\n",
      "Epoch 25/1000\n",
      "43/43 [==============================] - 1s 33ms/step - loss: 0.2085 - categorical_accuracy: 0.9193 - val_loss: 0.2198 - val_categorical_accuracy: 0.9033\n",
      "Epoch 26/1000\n",
      "43/43 [==============================] - 1s 33ms/step - loss: 0.1781 - categorical_accuracy: 0.9278 - val_loss: 0.2618 - val_categorical_accuracy: 0.9044\n",
      "Epoch 27/1000\n",
      "43/43 [==============================] - 1s 33ms/step - loss: 0.1938 - categorical_accuracy: 0.9270 - val_loss: 0.1782 - val_categorical_accuracy: 0.9300\n",
      "Epoch 28/1000\n",
      "43/43 [==============================] - 1s 34ms/step - loss: 0.1689 - categorical_accuracy: 0.9374 - val_loss: 0.2067 - val_categorical_accuracy: 0.9122\n",
      "Epoch 29/1000\n",
      "43/43 [==============================] - 1s 33ms/step - loss: 0.1726 - categorical_accuracy: 0.9352 - val_loss: 0.2267 - val_categorical_accuracy: 0.8956\n",
      "Epoch 30/1000\n",
      "43/43 [==============================] - 1s 35ms/step - loss: 0.2140 - categorical_accuracy: 0.9137 - val_loss: 0.1769 - val_categorical_accuracy: 0.9289\n",
      "Epoch 31/1000\n",
      "43/43 [==============================] - 1s 34ms/step - loss: 0.1769 - categorical_accuracy: 0.9315 - val_loss: 0.1860 - val_categorical_accuracy: 0.9122\n",
      "Epoch 32/1000\n",
      "43/43 [==============================] - 1s 33ms/step - loss: 0.1643 - categorical_accuracy: 0.9367 - val_loss: 0.1694 - val_categorical_accuracy: 0.9378\n",
      "Epoch 33/1000\n",
      "43/43 [==============================] - 1s 34ms/step - loss: 0.1740 - categorical_accuracy: 0.9337 - val_loss: 0.1714 - val_categorical_accuracy: 0.9289\n",
      "Epoch 34/1000\n",
      "43/43 [==============================] - 2s 35ms/step - loss: 0.1589 - categorical_accuracy: 0.9378 - val_loss: 0.1648 - val_categorical_accuracy: 0.9344\n",
      "Epoch 35/1000\n",
      "43/43 [==============================] - 1s 34ms/step - loss: 0.1480 - categorical_accuracy: 0.9400 - val_loss: 0.1579 - val_categorical_accuracy: 0.9378\n",
      "Epoch 36/1000\n",
      "43/43 [==============================] - 1s 33ms/step - loss: 0.1426 - categorical_accuracy: 0.9470 - val_loss: 0.2161 - val_categorical_accuracy: 0.9067\n",
      "Epoch 37/1000\n",
      "43/43 [==============================] - 1s 33ms/step - loss: 0.2509 - categorical_accuracy: 0.8856 - val_loss: 0.2062 - val_categorical_accuracy: 0.9011\n",
      "Epoch 38/1000\n",
      "43/43 [==============================] - 1s 33ms/step - loss: 0.1987 - categorical_accuracy: 0.9196 - val_loss: 0.1825 - val_categorical_accuracy: 0.9389\n",
      "Epoch 39/1000\n",
      "43/43 [==============================] - 1s 35ms/step - loss: 0.1726 - categorical_accuracy: 0.9278 - val_loss: 0.1867 - val_categorical_accuracy: 0.9333\n",
      "Epoch 40/1000\n",
      "43/43 [==============================] - 2s 39ms/step - loss: 0.1654 - categorical_accuracy: 0.9337 - val_loss: 0.2114 - val_categorical_accuracy: 0.9078\n",
      "Epoch 41/1000\n",
      "43/43 [==============================] - 2s 43ms/step - loss: 0.1569 - categorical_accuracy: 0.9396 - val_loss: 0.3536 - val_categorical_accuracy: 0.8611\n",
      "Epoch 42/1000\n",
      "43/43 [==============================] - 1s 33ms/step - loss: 0.2092 - categorical_accuracy: 0.9193 - val_loss: 0.1807 - val_categorical_accuracy: 0.9344\n",
      "Epoch 43/1000\n",
      "43/43 [==============================] - 1s 33ms/step - loss: 0.1578 - categorical_accuracy: 0.9370 - val_loss: 0.1903 - val_categorical_accuracy: 0.9233\n",
      "Epoch 44/1000\n",
      "43/43 [==============================] - 2s 38ms/step - loss: 0.1641 - categorical_accuracy: 0.9289 - val_loss: 0.1904 - val_categorical_accuracy: 0.9233\n",
      "Epoch 45/1000\n",
      "43/43 [==============================] - 1s 33ms/step - loss: 0.1906 - categorical_accuracy: 0.9263 - val_loss: 0.1657 - val_categorical_accuracy: 0.9333\n",
      "Epoch 46/1000\n",
      "43/43 [==============================] - 1s 33ms/step - loss: 0.1521 - categorical_accuracy: 0.9437 - val_loss: 0.1483 - val_categorical_accuracy: 0.9456\n",
      "Epoch 47/1000\n",
      "43/43 [==============================] - 2s 36ms/step - loss: 0.1343 - categorical_accuracy: 0.9496 - val_loss: 0.2003 - val_categorical_accuracy: 0.9189\n",
      "Epoch 48/1000\n",
      "43/43 [==============================] - 1s 32ms/step - loss: 0.1397 - categorical_accuracy: 0.9511 - val_loss: 0.1984 - val_categorical_accuracy: 0.9233\n",
      "Epoch 49/1000\n",
      "43/43 [==============================] - 1s 33ms/step - loss: 0.1914 - categorical_accuracy: 0.9289 - val_loss: 0.1622 - val_categorical_accuracy: 0.9367\n",
      "Epoch 50/1000\n",
      "43/43 [==============================] - 1s 34ms/step - loss: 0.1917 - categorical_accuracy: 0.9259 - val_loss: 0.1930 - val_categorical_accuracy: 0.9233\n",
      "Epoch 51/1000\n",
      "43/43 [==============================] - 1s 32ms/step - loss: 0.1378 - categorical_accuracy: 0.9485 - val_loss: 0.1730 - val_categorical_accuracy: 0.9356\n",
      "Epoch 52/1000\n",
      "43/43 [==============================] - 1s 32ms/step - loss: 0.1244 - categorical_accuracy: 0.9556 - val_loss: 0.1327 - val_categorical_accuracy: 0.9522\n",
      "Epoch 53/1000\n",
      "43/43 [==============================] - 2s 38ms/step - loss: 0.1798 - categorical_accuracy: 0.9322 - val_loss: 0.2554 - val_categorical_accuracy: 0.8978\n",
      "Epoch 54/1000\n",
      "43/43 [==============================] - 1s 33ms/step - loss: 0.1866 - categorical_accuracy: 0.9281 - val_loss: 0.1668 - val_categorical_accuracy: 0.9333\n",
      "Epoch 55/1000\n",
      "43/43 [==============================] - 1s 33ms/step - loss: 0.1491 - categorical_accuracy: 0.9452 - val_loss: 0.2064 - val_categorical_accuracy: 0.9067\n",
      "Epoch 56/1000\n",
      "43/43 [==============================] - 2s 36ms/step - loss: 0.1365 - categorical_accuracy: 0.9507 - val_loss: 0.1414 - val_categorical_accuracy: 0.9478\n",
      "Epoch 57/1000\n",
      "43/43 [==============================] - 2s 39ms/step - loss: 0.1255 - categorical_accuracy: 0.9496 - val_loss: 0.1665 - val_categorical_accuracy: 0.9333\n",
      "Epoch 58/1000\n",
      "43/43 [==============================] - 1s 34ms/step - loss: 0.1258 - categorical_accuracy: 0.9544 - val_loss: 0.1500 - val_categorical_accuracy: 0.9433\n",
      "Epoch 59/1000\n",
      "43/43 [==============================] - 2s 36ms/step - loss: 0.1309 - categorical_accuracy: 0.9481 - val_loss: 0.1359 - val_categorical_accuracy: 0.9533\n",
      "Epoch 60/1000\n",
      "43/43 [==============================] - 1s 34ms/step - loss: 0.1218 - categorical_accuracy: 0.9581 - val_loss: 0.1334 - val_categorical_accuracy: 0.9533\n",
      "Epoch 61/1000\n",
      "43/43 [==============================] - 1s 33ms/step - loss: 0.1312 - categorical_accuracy: 0.9519 - val_loss: 0.1212 - val_categorical_accuracy: 0.9567\n",
      "Epoch 62/1000\n",
      "43/43 [==============================] - 1s 33ms/step - loss: 0.1023 - categorical_accuracy: 0.9630 - val_loss: 0.1320 - val_categorical_accuracy: 0.9478\n",
      "Epoch 63/1000\n",
      "43/43 [==============================] - 1s 32ms/step - loss: 0.1672 - categorical_accuracy: 0.9363 - val_loss: 0.1755 - val_categorical_accuracy: 0.9344\n",
      "Epoch 64/1000\n",
      "43/43 [==============================] - 2s 35ms/step - loss: 0.1333 - categorical_accuracy: 0.9504 - val_loss: 0.1160 - val_categorical_accuracy: 0.9578\n",
      "Epoch 65/1000\n",
      "43/43 [==============================] - 1s 35ms/step - loss: 0.1101 - categorical_accuracy: 0.9619 - val_loss: 0.1428 - val_categorical_accuracy: 0.9456\n",
      "Epoch 66/1000\n",
      "43/43 [==============================] - 1s 34ms/step - loss: 0.1081 - categorical_accuracy: 0.9615 - val_loss: 0.1408 - val_categorical_accuracy: 0.9489\n",
      "Epoch 67/1000\n",
      "43/43 [==============================] - 1s 34ms/step - loss: 0.1185 - categorical_accuracy: 0.9611 - val_loss: 0.1695 - val_categorical_accuracy: 0.9300\n",
      "Epoch 68/1000\n",
      "43/43 [==============================] - 1s 31ms/step - loss: 0.1027 - categorical_accuracy: 0.9622 - val_loss: 0.1396 - val_categorical_accuracy: 0.9433\n",
      "Epoch 69/1000\n",
      "43/43 [==============================] - 1s 33ms/step - loss: 0.1133 - categorical_accuracy: 0.9563 - val_loss: 0.1621 - val_categorical_accuracy: 0.9389\n",
      "Epoch 70/1000\n",
      "43/43 [==============================] - 1s 33ms/step - loss: 0.1164 - categorical_accuracy: 0.9593 - val_loss: 0.1730 - val_categorical_accuracy: 0.9267\n",
      "Epoch 71/1000\n",
      "43/43 [==============================] - 1s 33ms/step - loss: 0.1136 - categorical_accuracy: 0.9604 - val_loss: 0.1071 - val_categorical_accuracy: 0.9611\n",
      "Epoch 72/1000\n",
      "43/43 [==============================] - 1s 32ms/step - loss: 0.1068 - categorical_accuracy: 0.9630 - val_loss: 0.1180 - val_categorical_accuracy: 0.9511\n",
      "Epoch 73/1000\n",
      "43/43 [==============================] - 1s 33ms/step - loss: 0.1188 - categorical_accuracy: 0.9537 - val_loss: 0.1321 - val_categorical_accuracy: 0.9567\n",
      "Epoch 74/1000\n",
      "43/43 [==============================] - 1s 33ms/step - loss: 0.1066 - categorical_accuracy: 0.9637 - val_loss: 0.1107 - val_categorical_accuracy: 0.9633\n",
      "Epoch 75/1000\n",
      "43/43 [==============================] - 1s 31ms/step - loss: 0.0882 - categorical_accuracy: 0.9656 - val_loss: 0.1559 - val_categorical_accuracy: 0.9456\n",
      "Epoch 76/1000\n",
      "43/43 [==============================] - 1s 33ms/step - loss: 0.1079 - categorical_accuracy: 0.9581 - val_loss: 0.1017 - val_categorical_accuracy: 0.9633\n",
      "Epoch 77/1000\n",
      "43/43 [==============================] - 1s 31ms/step - loss: 0.0921 - categorical_accuracy: 0.9652 - val_loss: 0.1299 - val_categorical_accuracy: 0.9567\n",
      "Epoch 78/1000\n",
      "43/43 [==============================] - 1s 33ms/step - loss: 0.0884 - categorical_accuracy: 0.9689 - val_loss: 0.1201 - val_categorical_accuracy: 0.9589\n",
      "Epoch 79/1000\n",
      "43/43 [==============================] - 1s 35ms/step - loss: 0.0820 - categorical_accuracy: 0.9730 - val_loss: 0.1489 - val_categorical_accuracy: 0.9500\n",
      "Epoch 80/1000\n",
      "43/43 [==============================] - 1s 31ms/step - loss: 0.0844 - categorical_accuracy: 0.9693 - val_loss: 0.1269 - val_categorical_accuracy: 0.9556\n",
      "Epoch 81/1000\n",
      "43/43 [==============================] - 1s 31ms/step - loss: 0.1323 - categorical_accuracy: 0.9556 - val_loss: 0.2282 - val_categorical_accuracy: 0.9211\n",
      "Epoch 82/1000\n",
      "43/43 [==============================] - 1s 34ms/step - loss: 0.1400 - categorical_accuracy: 0.9493 - val_loss: 0.1435 - val_categorical_accuracy: 0.9489\n",
      "Epoch 83/1000\n",
      "43/43 [==============================] - 1s 32ms/step - loss: 0.0995 - categorical_accuracy: 0.9659 - val_loss: 0.1067 - val_categorical_accuracy: 0.9600\n",
      "Epoch 84/1000\n",
      "43/43 [==============================] - 1s 32ms/step - loss: 0.1048 - categorical_accuracy: 0.9663 - val_loss: 0.1333 - val_categorical_accuracy: 0.9522\n",
      "Epoch 85/1000\n",
      "43/43 [==============================] - 2s 36ms/step - loss: 0.0861 - categorical_accuracy: 0.9722 - val_loss: 0.1216 - val_categorical_accuracy: 0.9633\n",
      "Epoch 86/1000\n",
      "43/43 [==============================] - 1s 31ms/step - loss: 0.1018 - categorical_accuracy: 0.9652 - val_loss: 0.1391 - val_categorical_accuracy: 0.9489\n",
      "Epoch 87/1000\n",
      "43/43 [==============================] - 1s 31ms/step - loss: 0.1262 - categorical_accuracy: 0.9570 - val_loss: 0.1524 - val_categorical_accuracy: 0.9511\n",
      "Epoch 88/1000\n",
      "43/43 [==============================] - 1s 33ms/step - loss: 0.1086 - categorical_accuracy: 0.9626 - val_loss: 0.1522 - val_categorical_accuracy: 0.9444\n",
      "Epoch 89/1000\n",
      "43/43 [==============================] - 1s 31ms/step - loss: 0.1246 - categorical_accuracy: 0.9552 - val_loss: 0.1263 - val_categorical_accuracy: 0.9467\n",
      "Epoch 90/1000\n",
      "43/43 [==============================] - 1s 30ms/step - loss: 0.0976 - categorical_accuracy: 0.9700 - val_loss: 0.1073 - val_categorical_accuracy: 0.9678\n",
      "Epoch 91/1000\n",
      "43/43 [==============================] - 2s 36ms/step - loss: 0.0896 - categorical_accuracy: 0.9674 - val_loss: 0.1121 - val_categorical_accuracy: 0.9622\n",
      "Epoch 92/1000\n",
      "43/43 [==============================] - 1s 31ms/step - loss: 0.0960 - categorical_accuracy: 0.9667 - val_loss: 0.1032 - val_categorical_accuracy: 0.9611\n",
      "Epoch 93/1000\n",
      "43/43 [==============================] - 1s 32ms/step - loss: 0.0873 - categorical_accuracy: 0.9722 - val_loss: 0.0997 - val_categorical_accuracy: 0.9678\n",
      "Epoch 94/1000\n",
      "43/43 [==============================] - 1s 34ms/step - loss: 0.1037 - categorical_accuracy: 0.9670 - val_loss: 0.1255 - val_categorical_accuracy: 0.9511\n",
      "Epoch 95/1000\n",
      "43/43 [==============================] - 1s 31ms/step - loss: 0.1087 - categorical_accuracy: 0.9604 - val_loss: 0.1502 - val_categorical_accuracy: 0.9433\n",
      "Epoch 96/1000\n",
      "43/43 [==============================] - 1s 30ms/step - loss: 0.0986 - categorical_accuracy: 0.9633 - val_loss: 0.1323 - val_categorical_accuracy: 0.9500\n",
      "Epoch 97/1000\n",
      "43/43 [==============================] - 2s 36ms/step - loss: 0.0764 - categorical_accuracy: 0.9722 - val_loss: 0.1019 - val_categorical_accuracy: 0.9711\n",
      "Epoch 98/1000\n",
      "43/43 [==============================] - 1s 35ms/step - loss: 0.0725 - categorical_accuracy: 0.9733 - val_loss: 0.0945 - val_categorical_accuracy: 0.9722\n",
      "Epoch 99/1000\n",
      "43/43 [==============================] - 1s 31ms/step - loss: 0.0871 - categorical_accuracy: 0.9689 - val_loss: 0.1366 - val_categorical_accuracy: 0.9433\n",
      "Epoch 100/1000\n",
      "43/43 [==============================] - 1s 33ms/step - loss: 0.0888 - categorical_accuracy: 0.9730 - val_loss: 0.1054 - val_categorical_accuracy: 0.9667\n",
      "Epoch 101/1000\n",
      "43/43 [==============================] - 1s 33ms/step - loss: 0.0744 - categorical_accuracy: 0.9763 - val_loss: 0.0938 - val_categorical_accuracy: 0.9722\n",
      "Epoch 102/1000\n",
      "43/43 [==============================] - 1s 33ms/step - loss: 0.0774 - categorical_accuracy: 0.9737 - val_loss: 0.1922 - val_categorical_accuracy: 0.9311\n",
      "Epoch 103/1000\n",
      "43/43 [==============================] - 1s 33ms/step - loss: 0.0933 - categorical_accuracy: 0.9685 - val_loss: 0.1192 - val_categorical_accuracy: 0.9556\n",
      "Epoch 104/1000\n",
      "43/43 [==============================] - 1s 34ms/step - loss: 0.1225 - categorical_accuracy: 0.9648 - val_loss: 0.2124 - val_categorical_accuracy: 0.9178\n",
      "Epoch 105/1000\n",
      "43/43 [==============================] - 1s 33ms/step - loss: 0.1448 - categorical_accuracy: 0.9437 - val_loss: 0.1505 - val_categorical_accuracy: 0.9444\n",
      "Epoch 106/1000\n",
      "43/43 [==============================] - 1s 33ms/step - loss: 0.0949 - categorical_accuracy: 0.9700 - val_loss: 0.1396 - val_categorical_accuracy: 0.9478\n",
      "Epoch 107/1000\n",
      "43/43 [==============================] - 1s 31ms/step - loss: 0.1019 - categorical_accuracy: 0.9619 - val_loss: 0.1214 - val_categorical_accuracy: 0.9567\n",
      "Epoch 108/1000\n",
      "43/43 [==============================] - 1s 35ms/step - loss: 0.0910 - categorical_accuracy: 0.9689 - val_loss: 0.1407 - val_categorical_accuracy: 0.9489\n",
      "Epoch 109/1000\n",
      "43/43 [==============================] - 1s 33ms/step - loss: 0.0784 - categorical_accuracy: 0.9733 - val_loss: 0.1282 - val_categorical_accuracy: 0.9611\n",
      "Epoch 110/1000\n",
      "43/43 [==============================] - 1s 31ms/step - loss: 0.0781 - categorical_accuracy: 0.9730 - val_loss: 0.1104 - val_categorical_accuracy: 0.9644\n",
      "Epoch 111/1000\n",
      "43/43 [==============================] - 2s 36ms/step - loss: 0.0864 - categorical_accuracy: 0.9678 - val_loss: 0.1582 - val_categorical_accuracy: 0.9533\n",
      "Epoch 112/1000\n",
      "43/43 [==============================] - 1s 33ms/step - loss: 0.0886 - categorical_accuracy: 0.9693 - val_loss: 0.0978 - val_categorical_accuracy: 0.9678\n",
      "Epoch 113/1000\n",
      "43/43 [==============================] - 1s 32ms/step - loss: 0.0793 - categorical_accuracy: 0.9700 - val_loss: 0.1008 - val_categorical_accuracy: 0.9700\n",
      "Epoch 114/1000\n",
      "43/43 [==============================] - 1s 34ms/step - loss: 0.0732 - categorical_accuracy: 0.9748 - val_loss: 0.1098 - val_categorical_accuracy: 0.9633\n",
      "Epoch 115/1000\n",
      "43/43 [==============================] - 2s 38ms/step - loss: 0.0691 - categorical_accuracy: 0.9763 - val_loss: 0.6205 - val_categorical_accuracy: 0.8833\n",
      "Epoch 116/1000\n",
      "43/43 [==============================] - 1s 31ms/step - loss: 0.1659 - categorical_accuracy: 0.9433 - val_loss: 0.1601 - val_categorical_accuracy: 0.9411\n",
      "Epoch 117/1000\n",
      "43/43 [==============================] - 2s 37ms/step - loss: 0.0863 - categorical_accuracy: 0.9693 - val_loss: 0.1238 - val_categorical_accuracy: 0.9589\n",
      "Epoch 118/1000\n",
      "43/43 [==============================] - 1s 30ms/step - loss: 0.0744 - categorical_accuracy: 0.9744 - val_loss: 0.1232 - val_categorical_accuracy: 0.9600\n",
      "Epoch 119/1000\n",
      "43/43 [==============================] - 1s 32ms/step - loss: 0.0666 - categorical_accuracy: 0.9778 - val_loss: 0.1289 - val_categorical_accuracy: 0.9578\n",
      "Epoch 120/1000\n",
      "43/43 [==============================] - 1s 34ms/step - loss: 0.0736 - categorical_accuracy: 0.9726 - val_loss: 0.1488 - val_categorical_accuracy: 0.9500\n",
      "Epoch 121/1000\n",
      "43/43 [==============================] - 2s 39ms/step - loss: 0.1508 - categorical_accuracy: 0.9426 - val_loss: 0.1970 - val_categorical_accuracy: 0.9311\n",
      "Epoch 122/1000\n",
      "43/43 [==============================] - 1s 34ms/step - loss: 0.1085 - categorical_accuracy: 0.9589 - val_loss: 0.1301 - val_categorical_accuracy: 0.9467\n",
      "Epoch 123/1000\n",
      "43/43 [==============================] - 2s 35ms/step - loss: 0.0820 - categorical_accuracy: 0.9696 - val_loss: 0.1065 - val_categorical_accuracy: 0.9611\n",
      "Epoch 124/1000\n",
      "43/43 [==============================] - 1s 32ms/step - loss: 0.0709 - categorical_accuracy: 0.9726 - val_loss: 0.1178 - val_categorical_accuracy: 0.9667\n",
      "Epoch 125/1000\n",
      "43/43 [==============================] - 1s 33ms/step - loss: 0.0775 - categorical_accuracy: 0.9707 - val_loss: 0.1070 - val_categorical_accuracy: 0.9700\n",
      "Epoch 126/1000\n",
      "43/43 [==============================] - 1s 32ms/step - loss: 0.0952 - categorical_accuracy: 0.9626 - val_loss: 0.1709 - val_categorical_accuracy: 0.9322\n",
      "Epoch 127/1000\n",
      "43/43 [==============================] - 1s 33ms/step - loss: 0.1192 - categorical_accuracy: 0.9570 - val_loss: 0.1513 - val_categorical_accuracy: 0.9456\n",
      "Epoch 128/1000\n",
      "43/43 [==============================] - 1s 34ms/step - loss: 0.0866 - categorical_accuracy: 0.9693 - val_loss: 0.1166 - val_categorical_accuracy: 0.9622\n",
      "Epoch 129/1000\n",
      "43/43 [==============================] - 1s 32ms/step - loss: 0.0740 - categorical_accuracy: 0.9741 - val_loss: 0.0923 - val_categorical_accuracy: 0.9644\n",
      "Epoch 130/1000\n",
      "43/43 [==============================] - 1s 34ms/step - loss: 0.0648 - categorical_accuracy: 0.9763 - val_loss: 0.0962 - val_categorical_accuracy: 0.9689\n",
      "Epoch 131/1000\n",
      "43/43 [==============================] - 1s 35ms/step - loss: 0.0649 - categorical_accuracy: 0.9778 - val_loss: 0.2108 - val_categorical_accuracy: 0.9367\n",
      "Epoch 132/1000\n",
      "43/43 [==============================] - 1s 32ms/step - loss: 0.1127 - categorical_accuracy: 0.9611 - val_loss: 0.1312 - val_categorical_accuracy: 0.9511\n",
      "Epoch 133/1000\n",
      "43/43 [==============================] - 1s 33ms/step - loss: 0.0781 - categorical_accuracy: 0.9711 - val_loss: 0.1372 - val_categorical_accuracy: 0.9511\n",
      "Epoch 134/1000\n",
      "43/43 [==============================] - 2s 35ms/step - loss: 0.0737 - categorical_accuracy: 0.9759 - val_loss: 0.1248 - val_categorical_accuracy: 0.9589\n",
      "Epoch 135/1000\n",
      "43/43 [==============================] - 1s 33ms/step - loss: 0.0713 - categorical_accuracy: 0.9752 - val_loss: 0.1146 - val_categorical_accuracy: 0.9578\n",
      "Epoch 136/1000\n",
      "43/43 [==============================] - 1s 34ms/step - loss: 0.0784 - categorical_accuracy: 0.9722 - val_loss: 0.1390 - val_categorical_accuracy: 0.9556\n",
      "Epoch 137/1000\n",
      "43/43 [==============================] - 2s 36ms/step - loss: 0.0795 - categorical_accuracy: 0.9704 - val_loss: 0.1236 - val_categorical_accuracy: 0.9578\n",
      "Epoch 138/1000\n",
      "43/43 [==============================] - 1s 33ms/step - loss: 0.0716 - categorical_accuracy: 0.9778 - val_loss: 0.1050 - val_categorical_accuracy: 0.9689\n",
      "Epoch 139/1000\n",
      "43/43 [==============================] - 1s 34ms/step - loss: 0.0641 - categorical_accuracy: 0.9744 - val_loss: 0.1176 - val_categorical_accuracy: 0.9600\n",
      "Epoch 140/1000\n",
      "43/43 [==============================] - 1s 33ms/step - loss: 0.0652 - categorical_accuracy: 0.9752 - val_loss: 0.1462 - val_categorical_accuracy: 0.9589\n",
      "Epoch 141/1000\n",
      "43/43 [==============================] - 1s 31ms/step - loss: 0.0715 - categorical_accuracy: 0.9763 - val_loss: 0.1241 - val_categorical_accuracy: 0.9611\n",
      "Epoch 142/1000\n",
      "43/43 [==============================] - 1s 34ms/step - loss: 0.0719 - categorical_accuracy: 0.9756 - val_loss: 0.1634 - val_categorical_accuracy: 0.9422\n",
      "Epoch 143/1000\n",
      "43/43 [==============================] - 2s 36ms/step - loss: 0.0845 - categorical_accuracy: 0.9711 - val_loss: 0.1118 - val_categorical_accuracy: 0.9578\n",
      "Epoch 144/1000\n",
      "43/43 [==============================] - 1s 35ms/step - loss: 0.0625 - categorical_accuracy: 0.9778 - val_loss: 0.1181 - val_categorical_accuracy: 0.9589\n",
      "Epoch 145/1000\n",
      "43/43 [==============================] - 1s 34ms/step - loss: 0.0851 - categorical_accuracy: 0.9685 - val_loss: 0.1368 - val_categorical_accuracy: 0.9511\n",
      "Epoch 146/1000\n",
      "43/43 [==============================] - 1s 34ms/step - loss: 0.0910 - categorical_accuracy: 0.9674 - val_loss: 0.1772 - val_categorical_accuracy: 0.9411\n",
      "Epoch 147/1000\n",
      "43/43 [==============================] - 1s 33ms/step - loss: 0.1015 - categorical_accuracy: 0.9633 - val_loss: 0.1208 - val_categorical_accuracy: 0.9578\n",
      "Epoch 148/1000\n",
      "43/43 [==============================] - 1s 34ms/step - loss: 0.0705 - categorical_accuracy: 0.9737 - val_loss: 0.1269 - val_categorical_accuracy: 0.9600\n",
      "Epoch 149/1000\n",
      "43/43 [==============================] - 2s 36ms/step - loss: 0.0615 - categorical_accuracy: 0.9770 - val_loss: 0.0955 - val_categorical_accuracy: 0.9733\n",
      "Epoch 150/1000\n",
      "42/43 [============================>.] - ETA: 0s - loss: 0.0640 - categorical_accuracy: 0.9803\n",
      "Accuracy grater than 0.95 so cancelling training!\n",
      "43/43 [==============================] - 2s 35ms/step - loss: 0.0638 - categorical_accuracy: 0.9804 - val_loss: 0.1168 - val_categorical_accuracy: 0.9633\n"
     ]
    }
   ],
   "source": [
    "# model_train = model.fit(X_train, y_train, epochs=10, batch_size=64,validation_data=(X_val,y_val), callbacks=[tb_callback])\n",
    "model_train = model.fit(X_train, y_train, epochs=1000, batch_size=64,validation_data=(X_val,y_val), callbacks=[callbacks])\n",
    "# model.fit(X_train, y_train, epochs=1000, callbacks=[tb_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 6s 181ms/step - loss: 2.7854 - categorical_accuracy: 0.0669 - val_loss: 2.7371 - val_categorical_accuracy: 0.1111\n",
      "Epoch 2/2\n",
      "16/16 [==============================] - 2s 157ms/step - loss: 2.7644 - categorical_accuracy: 0.0874 - val_loss: 2.7248 - val_categorical_accuracy: 0.1574\n",
      "Epoch 3/3\n",
      "16/16 [==============================] - 2s 154ms/step - loss: 2.7456 - categorical_accuracy: 0.0844 - val_loss: 2.7046 - val_categorical_accuracy: 0.2176\n",
      "Epoch 4/4\n",
      "16/16 [==============================] - 2s 153ms/step - loss: 2.7287 - categorical_accuracy: 0.1080 - val_loss: 2.6815 - val_categorical_accuracy: 0.2222\n",
      "Epoch 5/5\n",
      "16/16 [==============================] - 2s 155ms/step - loss: 2.7080 - categorical_accuracy: 0.0988 - val_loss: 2.6286 - val_categorical_accuracy: 0.2500\n",
      "Epoch 6/6\n",
      "16/16 [==============================] - 3s 166ms/step - loss: 2.6854 - categorical_accuracy: 0.1142 - val_loss: 2.5734 - val_categorical_accuracy: 0.2593\n",
      "Epoch 7/7\n",
      "16/16 [==============================] - 3s 168ms/step - loss: 2.6187 - categorical_accuracy: 0.1420 - val_loss: 2.4863 - val_categorical_accuracy: 0.2361\n",
      "Epoch 8/8\n",
      "16/16 [==============================] - 2s 154ms/step - loss: 2.5827 - categorical_accuracy: 0.1471 - val_loss: 2.4384 - val_categorical_accuracy: 0.2083\n",
      "Epoch 9/9\n",
      "38/38 [==============================] - 6s 152ms/step - loss: 2.5371 - categorical_accuracy: 0.1675 - val_loss: 2.3131 - val_categorical_accuracy: 0.3194\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 6s 148ms/step - loss: 2.4238 - categorical_accuracy: 0.1933 - val_loss: 2.2017 - val_categorical_accuracy: 0.3472\n",
      "Epoch 11/11\n",
      "31/31 [==============================] - 5s 149ms/step - loss: 2.3710 - categorical_accuracy: 0.2150 - val_loss: 2.0982 - val_categorical_accuracy: 0.3750\n",
      "Epoch 12/12\n",
      "31/31 [==============================] - 5s 146ms/step - loss: 2.2960 - categorical_accuracy: 0.2233 - val_loss: 2.0553 - val_categorical_accuracy: 0.4213\n",
      "Epoch 13/13\n",
      "16/16 [==============================] - 2s 156ms/step - loss: 2.2558 - categorical_accuracy: 0.2521 - val_loss: 1.9437 - val_categorical_accuracy: 0.4074\n",
      "Epoch 14/14\n",
      "16/16 [==============================] - 2s 153ms/step - loss: 2.2555 - categorical_accuracy: 0.2366 - val_loss: 2.0532 - val_categorical_accuracy: 0.4676\n",
      "Epoch 15/15\n",
      "16/16 [==============================] - 2s 153ms/step - loss: 2.1957 - categorical_accuracy: 0.2644 - val_loss: 1.9961 - val_categorical_accuracy: 0.4259\n",
      "Epoch 16/16\n",
      "16/16 [==============================] - 2s 154ms/step - loss: 2.1322 - categorical_accuracy: 0.2798 - val_loss: 1.8764 - val_categorical_accuracy: 0.4398\n",
      "Epoch 17/17\n",
      "16/16 [==============================] - 3s 158ms/step - loss: 2.2185 - categorical_accuracy: 0.2634 - val_loss: 1.8680 - val_categorical_accuracy: 0.4537\n",
      "Epoch 18/18\n",
      "16/16 [==============================] - 2s 152ms/step - loss: 2.1668 - categorical_accuracy: 0.2737 - val_loss: 1.9222 - val_categorical_accuracy: 0.4630\n",
      "Epoch 19/19\n",
      "16/16 [==============================] - 2s 154ms/step - loss: 2.1295 - categorical_accuracy: 0.2644 - val_loss: 1.8154 - val_categorical_accuracy: 0.4213\n",
      "Epoch 20/20\n",
      "16/16 [==============================] - 2s 152ms/step - loss: 2.0618 - categorical_accuracy: 0.3076 - val_loss: 1.7736 - val_categorical_accuracy: 0.3981\n",
      "Epoch 21/21\n",
      "38/38 [==============================] - 6s 153ms/step - loss: 2.0536 - categorical_accuracy: 0.3092 - val_loss: 1.6721 - val_categorical_accuracy: 0.5000\n",
      "Epoch 22/22\n",
      "38/38 [==============================] - 6s 147ms/step - loss: 1.9436 - categorical_accuracy: 0.3442 - val_loss: 1.5576 - val_categorical_accuracy: 0.4537\n",
      "Epoch 23/23\n",
      "31/31 [==============================] - 5s 148ms/step - loss: 1.9266 - categorical_accuracy: 0.3652 - val_loss: 1.4995 - val_categorical_accuracy: 0.5648\n",
      "Epoch 24/24\n",
      "31/31 [==============================] - 5s 148ms/step - loss: 1.9080 - categorical_accuracy: 0.3555 - val_loss: 1.5992 - val_categorical_accuracy: 0.5602\n",
      "Epoch 25/25\n",
      "16/16 [==============================] - 3s 158ms/step - loss: 1.7781 - categorical_accuracy: 0.4002 - val_loss: 1.4011 - val_categorical_accuracy: 0.5880\n",
      "Epoch 26/26\n",
      "16/16 [==============================] - 2s 153ms/step - loss: 1.7562 - categorical_accuracy: 0.4105 - val_loss: 1.3746 - val_categorical_accuracy: 0.6019\n",
      "Epoch 27/27\n",
      "16/16 [==============================] - 2s 150ms/step - loss: 1.7473 - categorical_accuracy: 0.4126 - val_loss: 1.4136 - val_categorical_accuracy: 0.5463\n",
      "Epoch 28/28\n",
      "16/16 [==============================] - 2s 154ms/step - loss: 1.7154 - categorical_accuracy: 0.4444 - val_loss: 1.4011 - val_categorical_accuracy: 0.5694\n",
      "Epoch 29/29\n",
      "16/16 [==============================] - 2s 154ms/step - loss: 1.7523 - categorical_accuracy: 0.4074 - val_loss: 1.3198 - val_categorical_accuracy: 0.5648\n",
      "Epoch 30/30\n",
      "16/16 [==============================] - 2s 151ms/step - loss: 1.7456 - categorical_accuracy: 0.3951 - val_loss: 1.2847 - val_categorical_accuracy: 0.5926\n",
      "Epoch 31/31\n",
      "16/16 [==============================] - 2s 151ms/step - loss: 1.7134 - categorical_accuracy: 0.4084 - val_loss: 1.2419 - val_categorical_accuracy: 0.6204\n",
      "Epoch 32/32\n",
      "16/16 [==============================] - 2s 149ms/step - loss: 1.6711 - categorical_accuracy: 0.4198 - val_loss: 1.2653 - val_categorical_accuracy: 0.5972\n",
      "Epoch 33/33\n",
      "38/38 [==============================] - 6s 146ms/step - loss: 1.6205 - categorical_accuracy: 0.4462 - val_loss: 1.1255 - val_categorical_accuracy: 0.6435\n",
      "Epoch 34/34\n",
      "38/38 [==============================] - 6s 146ms/step - loss: 1.5406 - categorical_accuracy: 0.4633 - val_loss: 1.0757 - val_categorical_accuracy: 0.6065\n",
      "Epoch 35/35\n",
      "31/31 [==============================] - 5s 150ms/step - loss: 1.4507 - categorical_accuracy: 0.4907 - val_loss: 1.0046 - val_categorical_accuracy: 0.6852\n",
      "Epoch 36/36\n",
      "31/31 [==============================] - 5s 146ms/step - loss: 1.4343 - categorical_accuracy: 0.5051 - val_loss: 1.0042 - val_categorical_accuracy: 0.7037\n",
      "Epoch 37/37\n",
      "16/16 [==============================] - 2s 156ms/step - loss: 1.3681 - categorical_accuracy: 0.5062 - val_loss: 0.9066 - val_categorical_accuracy: 0.6852\n",
      "Epoch 38/38\n",
      "16/16 [==============================] - 2s 156ms/step - loss: 1.3808 - categorical_accuracy: 0.5010 - val_loss: 0.9856 - val_categorical_accuracy: 0.6574\n",
      "Epoch 39/39\n",
      "16/16 [==============================] - 2s 151ms/step - loss: 1.3452 - categorical_accuracy: 0.5319 - val_loss: 0.9713 - val_categorical_accuracy: 0.6574\n",
      "Epoch 40/40\n",
      "16/16 [==============================] - 2s 156ms/step - loss: 1.3267 - categorical_accuracy: 0.5350 - val_loss: 0.8777 - val_categorical_accuracy: 0.6991\n",
      "Epoch 41/41\n",
      "16/16 [==============================] - 2s 151ms/step - loss: 1.4087 - categorical_accuracy: 0.5082 - val_loss: 0.9294 - val_categorical_accuracy: 0.6944\n",
      "Epoch 42/42\n",
      "16/16 [==============================] - 2s 151ms/step - loss: 1.3502 - categorical_accuracy: 0.5175 - val_loss: 0.8944 - val_categorical_accuracy: 0.6898\n",
      "Epoch 43/43\n",
      "16/16 [==============================] - 2s 151ms/step - loss: 1.3889 - categorical_accuracy: 0.4969 - val_loss: 0.8765 - val_categorical_accuracy: 0.6944\n",
      "Epoch 44/44\n",
      "16/16 [==============================] - 2s 151ms/step - loss: 1.3002 - categorical_accuracy: 0.5514 - val_loss: 0.8179 - val_categorical_accuracy: 0.7361\n",
      "Epoch 45/45\n",
      "38/38 [==============================] - 6s 148ms/step - loss: 1.2657 - categorical_accuracy: 0.5454 - val_loss: 0.7872 - val_categorical_accuracy: 0.7315\n",
      "Epoch 46/46\n",
      "38/38 [==============================] - 6s 146ms/step - loss: 1.2436 - categorical_accuracy: 0.5512 - val_loss: 0.8454 - val_categorical_accuracy: 0.7500\n",
      "Epoch 47/47\n",
      "31/31 [==============================] - 5s 148ms/step - loss: 1.1977 - categorical_accuracy: 0.5694 - val_loss: 0.7029 - val_categorical_accuracy: 0.7407\n",
      "Epoch 48/48\n",
      "31/31 [==============================] - 5s 147ms/step - loss: 1.1446 - categorical_accuracy: 0.5936 - val_loss: 0.7004 - val_categorical_accuracy: 0.7454\n",
      "Epoch 49/49\n",
      "16/16 [==============================] - 2s 150ms/step - loss: 1.0887 - categorical_accuracy: 0.6101 - val_loss: 0.7124 - val_categorical_accuracy: 0.7315\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 2s 151ms/step - loss: 1.0990 - categorical_accuracy: 0.6132 - val_loss: 0.8648 - val_categorical_accuracy: 0.7083\n",
      "Epoch 51/51\n",
      "16/16 [==============================] - 2s 151ms/step - loss: 1.2660 - categorical_accuracy: 0.5597 - val_loss: 0.8308 - val_categorical_accuracy: 0.6944\n",
      "Epoch 52/52\n",
      "16/16 [==============================] - 2s 154ms/step - loss: 1.1468 - categorical_accuracy: 0.5874 - val_loss: 0.8256 - val_categorical_accuracy: 0.6898\n",
      "Epoch 53/53\n",
      "16/16 [==============================] - 2s 152ms/step - loss: 1.2211 - categorical_accuracy: 0.5730 - val_loss: 0.7137 - val_categorical_accuracy: 0.7222\n",
      "Epoch 54/54\n",
      "16/16 [==============================] - 2s 149ms/step - loss: 1.1354 - categorical_accuracy: 0.5936 - val_loss: 0.7190 - val_categorical_accuracy: 0.6991\n",
      "Epoch 55/55\n",
      "16/16 [==============================] - 2s 157ms/step - loss: 1.1691 - categorical_accuracy: 0.5813 - val_loss: 0.7203 - val_categorical_accuracy: 0.7037\n",
      "Epoch 56/56\n",
      "16/16 [==============================] - 2s 151ms/step - loss: 1.1429 - categorical_accuracy: 0.5947 - val_loss: 0.7510 - val_categorical_accuracy: 0.6944\n",
      "Epoch 57/57\n",
      "38/38 [==============================] - 5s 145ms/step - loss: 1.0823 - categorical_accuracy: 0.6321 - val_loss: 0.7264 - val_categorical_accuracy: 0.7361\n",
      "Epoch 58/58\n",
      "38/38 [==============================] - 6s 146ms/step - loss: 1.0629 - categorical_accuracy: 0.6154 - val_loss: 0.6924 - val_categorical_accuracy: 0.7361\n",
      "Epoch 59/59\n",
      "31/31 [==============================] - 5s 150ms/step - loss: 1.0349 - categorical_accuracy: 0.6219 - val_loss: 0.6295 - val_categorical_accuracy: 0.7593\n",
      "Epoch 60/60\n",
      "31/31 [==============================] - 5s 148ms/step - loss: 0.9750 - categorical_accuracy: 0.6456 - val_loss: 0.6143 - val_categorical_accuracy: 0.7454\n",
      "Epoch 61/61\n",
      "16/16 [==============================] - 3s 156ms/step - loss: 0.8973 - categorical_accuracy: 0.6656 - val_loss: 0.6447 - val_categorical_accuracy: 0.7778\n",
      "Epoch 62/62\n",
      "16/16 [==============================] - 2s 152ms/step - loss: 0.9882 - categorical_accuracy: 0.6574 - val_loss: 0.7213 - val_categorical_accuracy: 0.7315\n",
      "Epoch 63/63\n",
      "16/16 [==============================] - 2s 155ms/step - loss: 1.0041 - categorical_accuracy: 0.6368 - val_loss: 0.6633 - val_categorical_accuracy: 0.7361\n",
      "Epoch 64/64\n",
      "16/16 [==============================] - 2s 157ms/step - loss: 0.9186 - categorical_accuracy: 0.6667 - val_loss: 0.5952 - val_categorical_accuracy: 0.7593\n",
      "Epoch 65/65\n",
      "16/16 [==============================] - 2s 149ms/step - loss: 0.9800 - categorical_accuracy: 0.6348 - val_loss: 0.6355 - val_categorical_accuracy: 0.7454\n",
      "Epoch 66/66\n",
      "16/16 [==============================] - 2s 151ms/step - loss: 1.1033 - categorical_accuracy: 0.6049 - val_loss: 0.6732 - val_categorical_accuracy: 0.7454\n",
      "Epoch 67/67\n",
      "16/16 [==============================] - 2s 149ms/step - loss: 1.0187 - categorical_accuracy: 0.6307 - val_loss: 0.6609 - val_categorical_accuracy: 0.7407\n",
      "Epoch 68/68\n",
      "16/16 [==============================] - 2s 152ms/step - loss: 0.9882 - categorical_accuracy: 0.6245 - val_loss: 0.6798 - val_categorical_accuracy: 0.7500\n",
      "Epoch 69/69\n",
      "38/38 [==============================] - 5s 144ms/step - loss: 0.9197 - categorical_accuracy: 0.6650 - val_loss: 0.5568 - val_categorical_accuracy: 0.8009\n",
      "Epoch 70/70\n",
      "38/38 [==============================] - 5s 145ms/step - loss: 0.9233 - categorical_accuracy: 0.6729 - val_loss: 0.5395 - val_categorical_accuracy: 0.8056\n",
      "Epoch 71/71\n",
      "31/31 [==============================] - 5s 155ms/step - loss: 0.8508 - categorical_accuracy: 0.7001 - val_loss: 0.5043 - val_categorical_accuracy: 0.8426\n",
      "Epoch 72/72\n",
      "31/31 [==============================] - 5s 149ms/step - loss: 0.7926 - categorical_accuracy: 0.7109 - val_loss: 0.5107 - val_categorical_accuracy: 0.8287\n",
      "Epoch 73/73\n",
      "16/16 [==============================] - 3s 163ms/step - loss: 0.8126 - categorical_accuracy: 0.7006 - val_loss: 0.5229 - val_categorical_accuracy: 0.8056\n",
      "Epoch 74/74\n",
      "16/16 [==============================] - 2s 150ms/step - loss: 0.7630 - categorical_accuracy: 0.7150 - val_loss: 0.4946 - val_categorical_accuracy: 0.8194\n",
      "Epoch 75/75\n",
      "16/16 [==============================] - 2s 152ms/step - loss: 0.7465 - categorical_accuracy: 0.7253 - val_loss: 0.5221 - val_categorical_accuracy: 0.8102\n",
      "Epoch 76/76\n",
      "16/16 [==============================] - 2s 150ms/step - loss: 0.7653 - categorical_accuracy: 0.7212 - val_loss: 0.5042 - val_categorical_accuracy: 0.8287\n",
      "Epoch 77/77\n",
      "16/16 [==============================] - 2s 150ms/step - loss: 0.8601 - categorical_accuracy: 0.6965 - val_loss: 0.5608 - val_categorical_accuracy: 0.7731\n",
      "Epoch 78/78\n",
      "16/16 [==============================] - 2s 150ms/step - loss: 0.7716 - categorical_accuracy: 0.7016 - val_loss: 0.5275 - val_categorical_accuracy: 0.8148\n",
      "Epoch 79/79\n",
      "16/16 [==============================] - 2s 151ms/step - loss: 0.8074 - categorical_accuracy: 0.6934 - val_loss: 0.5417 - val_categorical_accuracy: 0.7824\n",
      "Epoch 80/80\n",
      "16/16 [==============================] - 2s 151ms/step - loss: 0.8538 - categorical_accuracy: 0.6965 - val_loss: 0.5561 - val_categorical_accuracy: 0.8009\n",
      "Epoch 81/81\n",
      "38/38 [==============================] - 5s 143ms/step - loss: 0.7916 - categorical_accuracy: 0.7033 - val_loss: 0.4923 - val_categorical_accuracy: 0.8241\n",
      "Epoch 82/82\n",
      "38/38 [==============================] - 6s 145ms/step - loss: 0.7901 - categorical_accuracy: 0.7025 - val_loss: 0.4833 - val_categorical_accuracy: 0.8241\n",
      "Epoch 83/83\n",
      "31/31 [==============================] - 5s 148ms/step - loss: 0.7496 - categorical_accuracy: 0.7335 - val_loss: 0.5007 - val_categorical_accuracy: 0.8194\n",
      "Epoch 84/84\n",
      "31/31 [==============================] - 5s 146ms/step - loss: 0.6982 - categorical_accuracy: 0.7315 - val_loss: 0.4866 - val_categorical_accuracy: 0.8241\n",
      "Epoch 85/85\n",
      "16/16 [==============================] - 2s 151ms/step - loss: 0.7451 - categorical_accuracy: 0.7407 - val_loss: 0.5281 - val_categorical_accuracy: 0.8056\n",
      "Epoch 86/86\n",
      "16/16 [==============================] - 2s 150ms/step - loss: 0.7146 - categorical_accuracy: 0.7191 - val_loss: 0.4477 - val_categorical_accuracy: 0.8194\n",
      "Epoch 87/87\n",
      "16/16 [==============================] - 2s 152ms/step - loss: 0.6771 - categorical_accuracy: 0.7613 - val_loss: 0.4658 - val_categorical_accuracy: 0.8472\n",
      "Epoch 88/88\n",
      "16/16 [==============================] - 2s 154ms/step - loss: 0.6932 - categorical_accuracy: 0.7315 - val_loss: 0.4464 - val_categorical_accuracy: 0.8380\n",
      "Epoch 89/89\n",
      "16/16 [==============================] - 2s 154ms/step - loss: 0.7466 - categorical_accuracy: 0.7387 - val_loss: 0.4528 - val_categorical_accuracy: 0.8333\n",
      "Epoch 90/90\n",
      "16/16 [==============================] - 2s 153ms/step - loss: 0.6996 - categorical_accuracy: 0.7397 - val_loss: 0.4957 - val_categorical_accuracy: 0.8102\n",
      "Epoch 91/91\n",
      "16/16 [==============================] - 3s 162ms/step - loss: 0.7250 - categorical_accuracy: 0.7335 - val_loss: 0.4544 - val_categorical_accuracy: 0.8333\n",
      "Epoch 92/92\n",
      "16/16 [==============================] - 3s 158ms/step - loss: 0.7525 - categorical_accuracy: 0.7202 - val_loss: 0.4761 - val_categorical_accuracy: 0.8472\n",
      "Epoch 93/93\n",
      "38/38 [==============================] - 6s 154ms/step - loss: 0.7016 - categorical_accuracy: 0.7362 - val_loss: 0.4127 - val_categorical_accuracy: 0.8657\n",
      "Epoch 94/94\n",
      "38/38 [==============================] - 6s 145ms/step - loss: 0.7344 - categorical_accuracy: 0.7404 - val_loss: 0.4343 - val_categorical_accuracy: 0.8380\n",
      "Epoch 95/95\n",
      "31/31 [==============================] - 5s 148ms/step - loss: 0.6662 - categorical_accuracy: 0.7582 - val_loss: 0.4011 - val_categorical_accuracy: 0.8426\n",
      "Epoch 96/96\n",
      "31/31 [==============================] - 4s 143ms/step - loss: 0.6121 - categorical_accuracy: 0.7716 - val_loss: 0.4107 - val_categorical_accuracy: 0.8704\n",
      "Epoch 97/97\n",
      "16/16 [==============================] - 2s 151ms/step - loss: 0.5898 - categorical_accuracy: 0.7809 - val_loss: 0.4229 - val_categorical_accuracy: 0.8611\n",
      "Epoch 98/98\n",
      "16/16 [==============================] - 2s 154ms/step - loss: 0.5843 - categorical_accuracy: 0.7767 - val_loss: 0.4393 - val_categorical_accuracy: 0.8519\n",
      "Epoch 99/99\n",
      "16/16 [==============================] - 2s 148ms/step - loss: 0.5878 - categorical_accuracy: 0.7860 - val_loss: 0.4291 - val_categorical_accuracy: 0.8472\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 2s 146ms/step - loss: 0.5701 - categorical_accuracy: 0.7881 - val_loss: 0.3769 - val_categorical_accuracy: 0.8472\n",
      "Epoch 101/101\n",
      "16/16 [==============================] - 2s 148ms/step - loss: 0.6662 - categorical_accuracy: 0.7541 - val_loss: 0.4618 - val_categorical_accuracy: 0.8519\n",
      "Epoch 102/102\n",
      "16/16 [==============================] - 2s 148ms/step - loss: 0.6453 - categorical_accuracy: 0.7695 - val_loss: 0.3853 - val_categorical_accuracy: 0.8611\n",
      "Epoch 103/103\n",
      "16/16 [==============================] - 3s 158ms/step - loss: 0.6505 - categorical_accuracy: 0.7788 - val_loss: 0.4395 - val_categorical_accuracy: 0.8519\n",
      "Epoch 104/104\n",
      "16/16 [==============================] - 2s 151ms/step - loss: 0.6526 - categorical_accuracy: 0.7809 - val_loss: 0.4001 - val_categorical_accuracy: 0.8750\n",
      "Epoch 105/105\n",
      "38/38 [==============================] - 5s 142ms/step - loss: 0.6227 - categorical_accuracy: 0.7671 - val_loss: 0.3917 - val_categorical_accuracy: 0.8843\n",
      "Epoch 106/106\n",
      "38/38 [==============================] - 5s 143ms/step - loss: 0.5968 - categorical_accuracy: 0.7742 - val_loss: 0.2974 - val_categorical_accuracy: 0.8981\n",
      "Epoch 107/107\n",
      "31/31 [==============================] - 4s 144ms/step - loss: 0.5717 - categorical_accuracy: 0.7942 - val_loss: 0.4070 - val_categorical_accuracy: 0.8472\n",
      "Epoch 108/108\n",
      "31/31 [==============================] - 4s 145ms/step - loss: 0.5130 - categorical_accuracy: 0.8112 - val_loss: 0.3126 - val_categorical_accuracy: 0.8843\n",
      "Epoch 109/109\n",
      "16/16 [==============================] - 2s 148ms/step - loss: 0.5045 - categorical_accuracy: 0.8179 - val_loss: 0.2993 - val_categorical_accuracy: 0.8843\n",
      "Epoch 110/110\n",
      "16/16 [==============================] - 2s 148ms/step - loss: 0.6147 - categorical_accuracy: 0.7912 - val_loss: 0.3871 - val_categorical_accuracy: 0.8704\n",
      "Epoch 111/111\n",
      "16/16 [==============================] - 2s 148ms/step - loss: 0.5768 - categorical_accuracy: 0.7767 - val_loss: 0.3725 - val_categorical_accuracy: 0.8704\n",
      "Epoch 112/112\n",
      "16/16 [==============================] - 2s 155ms/step - loss: 0.5531 - categorical_accuracy: 0.8045 - val_loss: 0.3772 - val_categorical_accuracy: 0.8843\n",
      "Epoch 113/113\n",
      "16/16 [==============================] - 2s 148ms/step - loss: 0.6057 - categorical_accuracy: 0.7901 - val_loss: 0.4109 - val_categorical_accuracy: 0.8611\n",
      "Epoch 114/114\n",
      "16/16 [==============================] - 2s 150ms/step - loss: 0.5752 - categorical_accuracy: 0.7973 - val_loss: 0.4121 - val_categorical_accuracy: 0.8426\n",
      "Epoch 115/115\n",
      "16/16 [==============================] - 2s 148ms/step - loss: 0.6145 - categorical_accuracy: 0.7901 - val_loss: 0.3715 - val_categorical_accuracy: 0.8843\n",
      "Epoch 116/116\n",
      "16/16 [==============================] - 2s 149ms/step - loss: 0.6078 - categorical_accuracy: 0.7891 - val_loss: 0.3694 - val_categorical_accuracy: 0.8611\n",
      "Epoch 117/117\n",
      "38/38 [==============================] - 5s 142ms/step - loss: 0.5237 - categorical_accuracy: 0.8138 - val_loss: 0.2872 - val_categorical_accuracy: 0.8981\n",
      "Epoch 118/118\n",
      "38/38 [==============================] - 5s 143ms/step - loss: 0.5241 - categorical_accuracy: 0.8054 - val_loss: 0.2679 - val_categorical_accuracy: 0.9213\n",
      "Epoch 119/119\n",
      "31/31 [==============================] - 4s 143ms/step - loss: 0.4537 - categorical_accuracy: 0.8287 - val_loss: 0.3092 - val_categorical_accuracy: 0.9028\n",
      "Epoch 120/120\n",
      "31/31 [==============================] - 4s 144ms/step - loss: 0.5029 - categorical_accuracy: 0.8189 - val_loss: 0.3210 - val_categorical_accuracy: 0.8889\n",
      "Epoch 121/121\n",
      "16/16 [==============================] - 3s 158ms/step - loss: 0.5057 - categorical_accuracy: 0.8189 - val_loss: 0.2877 - val_categorical_accuracy: 0.9306\n",
      "Epoch 122/122\n",
      "16/16 [==============================] - 2s 147ms/step - loss: 0.4955 - categorical_accuracy: 0.8200 - val_loss: 0.3749 - val_categorical_accuracy: 0.8796\n",
      "Epoch 123/123\n",
      "16/16 [==============================] - 2s 149ms/step - loss: 0.4638 - categorical_accuracy: 0.8292 - val_loss: 0.4046 - val_categorical_accuracy: 0.8843\n",
      "Epoch 124/124\n",
      "16/16 [==============================] - 2s 147ms/step - loss: 0.5443 - categorical_accuracy: 0.8097 - val_loss: 0.3932 - val_categorical_accuracy: 0.8935\n",
      "Epoch 125/125\n",
      "16/16 [==============================] - 2s 148ms/step - loss: 0.6120 - categorical_accuracy: 0.7809 - val_loss: 0.3201 - val_categorical_accuracy: 0.8796\n",
      "Epoch 126/126\n",
      "16/16 [==============================] - 2s 151ms/step - loss: 0.6131 - categorical_accuracy: 0.7870 - val_loss: 0.3073 - val_categorical_accuracy: 0.8981\n",
      "Epoch 127/127\n",
      "16/16 [==============================] - 2s 149ms/step - loss: 0.5068 - categorical_accuracy: 0.8230 - val_loss: 0.4217 - val_categorical_accuracy: 0.8843\n",
      "Epoch 128/128\n",
      "16/16 [==============================] - 2s 146ms/step - loss: 0.5004 - categorical_accuracy: 0.8128 - val_loss: 0.3095 - val_categorical_accuracy: 0.8889\n",
      "Epoch 129/129\n",
      "38/38 [==============================] - 5s 144ms/step - loss: 0.5216 - categorical_accuracy: 0.8283 - val_loss: 0.2711 - val_categorical_accuracy: 0.9074\n",
      "Epoch 130/130\n",
      "38/38 [==============================] - 5s 144ms/step - loss: 0.4928 - categorical_accuracy: 0.8296 - val_loss: 0.2470 - val_categorical_accuracy: 0.9074\n",
      "Epoch 131/131\n",
      "31/31 [==============================] - 5s 161ms/step - loss: 0.4352 - categorical_accuracy: 0.8410 - val_loss: 0.3088 - val_categorical_accuracy: 0.9120\n",
      "Epoch 132/132\n",
      "31/31 [==============================] - 4s 144ms/step - loss: 0.4010 - categorical_accuracy: 0.8513 - val_loss: 0.2961 - val_categorical_accuracy: 0.9259\n",
      "Epoch 133/133\n",
      "16/16 [==============================] - 2s 149ms/step - loss: 0.4595 - categorical_accuracy: 0.8385 - val_loss: 0.2469 - val_categorical_accuracy: 0.9213\n",
      "Epoch 134/134\n",
      "16/16 [==============================] - 2s 148ms/step - loss: 0.3806 - categorical_accuracy: 0.8570 - val_loss: 0.2271 - val_categorical_accuracy: 0.9306\n",
      "Epoch 135/135\n",
      "16/16 [==============================] - 2s 151ms/step - loss: 0.4428 - categorical_accuracy: 0.8385 - val_loss: 0.3202 - val_categorical_accuracy: 0.8889\n",
      "Epoch 136/136\n",
      "16/16 [==============================] - 2s 148ms/step - loss: 0.4575 - categorical_accuracy: 0.8302 - val_loss: 0.2483 - val_categorical_accuracy: 0.9213\n",
      "Epoch 137/137\n",
      "16/16 [==============================] - 2s 151ms/step - loss: 0.4991 - categorical_accuracy: 0.8200 - val_loss: 0.2318 - val_categorical_accuracy: 0.9259\n",
      "Epoch 138/138\n",
      "16/16 [==============================] - 2s 148ms/step - loss: 0.4350 - categorical_accuracy: 0.8364 - val_loss: 0.2207 - val_categorical_accuracy: 0.9306\n",
      "Epoch 139/139\n",
      "16/16 [==============================] - 2s 149ms/step - loss: 0.4625 - categorical_accuracy: 0.8364 - val_loss: 0.2632 - val_categorical_accuracy: 0.9167\n",
      "Epoch 140/140\n",
      "16/16 [==============================] - 2s 148ms/step - loss: 0.4631 - categorical_accuracy: 0.8220 - val_loss: 0.2049 - val_categorical_accuracy: 0.9352\n",
      "Epoch 141/141\n",
      "38/38 [==============================] - 5s 142ms/step - loss: 0.4467 - categorical_accuracy: 0.8496 - val_loss: 0.1973 - val_categorical_accuracy: 0.9352\n",
      "Epoch 142/142\n",
      "38/38 [==============================] - 5s 141ms/step - loss: 0.4666 - categorical_accuracy: 0.8462 - val_loss: 0.2214 - val_categorical_accuracy: 0.9213\n",
      "Epoch 143/143\n",
      "31/31 [==============================] - 4s 142ms/step - loss: 0.4406 - categorical_accuracy: 0.8374 - val_loss: 0.2866 - val_categorical_accuracy: 0.9120\n",
      "Epoch 144/144\n",
      "31/31 [==============================] - 5s 146ms/step - loss: 0.4956 - categorical_accuracy: 0.8277 - val_loss: 0.2308 - val_categorical_accuracy: 0.9352\n",
      "Epoch 145/145\n",
      "16/16 [==============================] - 3s 157ms/step - loss: 0.3958 - categorical_accuracy: 0.8519 - val_loss: 0.3170 - val_categorical_accuracy: 0.8981\n",
      "Epoch 146/146\n",
      "16/16 [==============================] - 2s 148ms/step - loss: 0.4260 - categorical_accuracy: 0.8632 - val_loss: 0.3756 - val_categorical_accuracy: 0.8796\n",
      "Epoch 147/147\n",
      "16/16 [==============================] - 2s 147ms/step - loss: 0.4188 - categorical_accuracy: 0.8498 - val_loss: 0.2303 - val_categorical_accuracy: 0.9120\n",
      "Epoch 148/148\n",
      "16/16 [==============================] - 2s 150ms/step - loss: 0.3374 - categorical_accuracy: 0.8673 - val_loss: 0.2965 - val_categorical_accuracy: 0.9167\n",
      "Epoch 149/149\n",
      "16/16 [==============================] - 2s 148ms/step - loss: 0.3933 - categorical_accuracy: 0.8529 - val_loss: 0.2986 - val_categorical_accuracy: 0.9306\n",
      "Epoch 150/150\n",
      "16/16 [==============================] - 2s 149ms/step - loss: 0.4289 - categorical_accuracy: 0.8272 - val_loss: 0.2600 - val_categorical_accuracy: 0.9213\n",
      "Epoch 151/151\n",
      "31/31 [==============================] - 4s 143ms/step - loss: 0.3978 - categorical_accuracy: 0.8606 - val_loss: 0.2078 - val_categorical_accuracy: 0.9398\n",
      "Epoch 152/152\n",
      "31/31 [==============================] - 4s 142ms/step - loss: 0.3769 - categorical_accuracy: 0.8663 - val_loss: 0.2247 - val_categorical_accuracy: 0.9352\n",
      "Epoch 153/153\n",
      "31/31 [==============================] - 4s 145ms/step - loss: 0.4680 - categorical_accuracy: 0.8544 - val_loss: 0.3918 - val_categorical_accuracy: 0.8472\n",
      "Epoch 154/154\n",
      "31/31 [==============================] - 4s 143ms/step - loss: 0.5254 - categorical_accuracy: 0.8241 - val_loss: 0.2352 - val_categorical_accuracy: 0.9306\n",
      "Epoch 155/155\n",
      "31/31 [==============================] - 5s 147ms/step - loss: 0.4167 - categorical_accuracy: 0.8534 - val_loss: 0.2270 - val_categorical_accuracy: 0.9213\n",
      "Epoch 156/156\n",
      "31/31 [==============================] - 4s 142ms/step - loss: 0.3688 - categorical_accuracy: 0.8688 - val_loss: 0.1865 - val_categorical_accuracy: 0.9398\n",
      "Epoch 157/157\n",
      "31/31 [==============================] - 4s 142ms/step - loss: 0.3529 - categorical_accuracy: 0.8729 - val_loss: 0.1664 - val_categorical_accuracy: 0.9444\n",
      "Epoch 158/158\n",
      "31/31 [==============================] - 4s 142ms/step - loss: 0.3259 - categorical_accuracy: 0.8827 - val_loss: 0.2014 - val_categorical_accuracy: 0.9398\n",
      "Epoch 159/159\n",
      "31/31 [==============================] - 4s 140ms/step - loss: 0.3289 - categorical_accuracy: 0.8873 - val_loss: 0.1939 - val_categorical_accuracy: 0.9398\n",
      "Epoch 160/160\n",
      "31/31 [==============================] - 4s 141ms/step - loss: 0.3784 - categorical_accuracy: 0.8673 - val_loss: 0.2471 - val_categorical_accuracy: 0.9352\n",
      "Epoch 161/161\n",
      "31/31 [==============================] - 4s 143ms/step - loss: 0.4200 - categorical_accuracy: 0.8627 - val_loss: 0.2540 - val_categorical_accuracy: 0.9213\n",
      "Epoch 162/162\n",
      "31/31 [==============================] - 4s 144ms/step - loss: 0.3698 - categorical_accuracy: 0.8673 - val_loss: 0.2188 - val_categorical_accuracy: 0.9352\n",
      "Epoch 163/163\n",
      "31/31 [==============================] - 4s 145ms/step - loss: 0.3718 - categorical_accuracy: 0.8678 - val_loss: 0.2075 - val_categorical_accuracy: 0.9306\n",
      "Epoch 164/164\n",
      "31/31 [==============================] - 4s 143ms/step - loss: 0.3278 - categorical_accuracy: 0.8832 - val_loss: 0.2152 - val_categorical_accuracy: 0.9398\n",
      "Epoch 165/165\n",
      "31/31 [==============================] - 4s 141ms/step - loss: 0.3128 - categorical_accuracy: 0.8920 - val_loss: 0.1871 - val_categorical_accuracy: 0.9491\n",
      "Epoch 166/166\n",
      "31/31 [==============================] - 4s 142ms/step - loss: 0.3031 - categorical_accuracy: 0.8909 - val_loss: 0.1977 - val_categorical_accuracy: 0.9444\n",
      "Epoch 167/167\n",
      "31/31 [==============================] - 4s 141ms/step - loss: 0.3047 - categorical_accuracy: 0.8971 - val_loss: 0.2711 - val_categorical_accuracy: 0.9259\n",
      "Epoch 168/168\n",
      "31/31 [==============================] - 4s 141ms/step - loss: 0.3320 - categorical_accuracy: 0.8832 - val_loss: 0.2143 - val_categorical_accuracy: 0.9306\n",
      "Epoch 169/169\n",
      "31/31 [==============================] - 4s 142ms/step - loss: 0.3607 - categorical_accuracy: 0.8904 - val_loss: 0.2692 - val_categorical_accuracy: 0.9120\n",
      "Epoch 170/170\n",
      "31/31 [==============================] - 5s 145ms/step - loss: 0.3338 - categorical_accuracy: 0.8817 - val_loss: 0.2902 - val_categorical_accuracy: 0.9444\n",
      "Epoch 171/171\n",
      "31/31 [==============================] - 4s 141ms/step - loss: 0.3206 - categorical_accuracy: 0.8884 - val_loss: 0.2927 - val_categorical_accuracy: 0.9352\n",
      "Epoch 172/172\n",
      "31/31 [==============================] - 4s 140ms/step - loss: 0.3338 - categorical_accuracy: 0.8822 - val_loss: 0.2542 - val_categorical_accuracy: 0.9352\n",
      "Epoch 173/173\n",
      "31/31 [==============================] - 4s 143ms/step - loss: 0.3185 - categorical_accuracy: 0.8956 - val_loss: 0.2427 - val_categorical_accuracy: 0.9259\n",
      "Epoch 174/174\n",
      "31/31 [==============================] - 4s 140ms/step - loss: 0.3413 - categorical_accuracy: 0.8822 - val_loss: 0.2477 - val_categorical_accuracy: 0.9352\n",
      "Epoch 175/175\n",
      "31/31 [==============================] - 4s 144ms/step - loss: 0.3337 - categorical_accuracy: 0.8879 - val_loss: 0.2683 - val_categorical_accuracy: 0.9167\n",
      "Epoch 176/176\n",
      "31/31 [==============================] - 4s 142ms/step - loss: 0.4445 - categorical_accuracy: 0.8621 - val_loss: 0.2926 - val_categorical_accuracy: 0.9444\n",
      "Epoch 177/177\n",
      "31/31 [==============================] - 4s 141ms/step - loss: 0.3222 - categorical_accuracy: 0.8909 - val_loss: 0.1729 - val_categorical_accuracy: 0.9537\n",
      "Epoch 178/178\n",
      "31/31 [==============================] - 5s 146ms/step - loss: 0.3048 - categorical_accuracy: 0.8971 - val_loss: 0.2333 - val_categorical_accuracy: 0.9398\n",
      "Epoch 179/179\n",
      "31/31 [==============================] - 4s 140ms/step - loss: 0.2736 - categorical_accuracy: 0.9064 - val_loss: 0.3496 - val_categorical_accuracy: 0.9259\n",
      "Epoch 180/180\n",
      "31/31 [==============================] - 4s 142ms/step - loss: 0.3364 - categorical_accuracy: 0.8863 - val_loss: 0.2658 - val_categorical_accuracy: 0.9398\n",
      "Epoch 181/181\n",
      "31/31 [==============================] - 4s 141ms/step - loss: 0.3075 - categorical_accuracy: 0.8971 - val_loss: 0.4867 - val_categorical_accuracy: 0.8657\n",
      "Epoch 182/182\n",
      "31/31 [==============================] - 4s 142ms/step - loss: 0.5250 - categorical_accuracy: 0.8349 - val_loss: 0.2325 - val_categorical_accuracy: 0.9352\n",
      "Epoch 183/183\n",
      "31/31 [==============================] - 4s 143ms/step - loss: 0.2952 - categorical_accuracy: 0.9002 - val_loss: 0.1600 - val_categorical_accuracy: 0.9444\n",
      "Epoch 184/184\n",
      "31/31 [==============================] - 4s 142ms/step - loss: 0.2969 - categorical_accuracy: 0.9012 - val_loss: 0.1599 - val_categorical_accuracy: 0.9537\n",
      "Epoch 185/185\n",
      "31/31 [==============================] - 4s 144ms/step - loss: 0.2898 - categorical_accuracy: 0.9059 - val_loss: 0.2451 - val_categorical_accuracy: 0.9306\n",
      "Epoch 186/186\n",
      "31/31 [==============================] - 4s 141ms/step - loss: 0.3315 - categorical_accuracy: 0.8853 - val_loss: 0.3204 - val_categorical_accuracy: 0.9167\n",
      "Epoch 187/187\n",
      "31/31 [==============================] - 4s 140ms/step - loss: 0.3226 - categorical_accuracy: 0.8971 - val_loss: 0.2311 - val_categorical_accuracy: 0.9444\n",
      "Epoch 188/188\n",
      "31/31 [==============================] - 4s 142ms/step - loss: 0.2857 - categorical_accuracy: 0.8961 - val_loss: 0.2177 - val_categorical_accuracy: 0.9398\n",
      "Epoch 189/189\n",
      "31/31 [==============================] - 4s 141ms/step - loss: 0.2632 - categorical_accuracy: 0.9115 - val_loss: 0.2696 - val_categorical_accuracy: 0.9537\n",
      "Epoch 190/190\n",
      "31/31 [==============================] - 4s 142ms/step - loss: 0.2460 - categorical_accuracy: 0.9172 - val_loss: 0.3442 - val_categorical_accuracy: 0.9259\n",
      "Epoch 191/191\n",
      "31/31 [==============================] - 4s 143ms/step - loss: 0.2585 - categorical_accuracy: 0.9074 - val_loss: 0.1205 - val_categorical_accuracy: 0.9722\n",
      "Epoch 192/192\n",
      "31/31 [==============================] - 4s 142ms/step - loss: 0.2442 - categorical_accuracy: 0.9177 - val_loss: 0.1369 - val_categorical_accuracy: 0.9676\n",
      "Epoch 193/193\n",
      "31/31 [==============================] - 4s 144ms/step - loss: 0.2379 - categorical_accuracy: 0.9264 - val_loss: 0.1609 - val_categorical_accuracy: 0.9491\n",
      "Epoch 194/194\n",
      "31/31 [==============================] - 4s 141ms/step - loss: 0.2425 - categorical_accuracy: 0.9218 - val_loss: 0.2266 - val_categorical_accuracy: 0.9630\n",
      "Epoch 195/195\n",
      "31/31 [==============================] - 4s 140ms/step - loss: 0.2470 - categorical_accuracy: 0.9172 - val_loss: 0.1741 - val_categorical_accuracy: 0.9444\n",
      "Epoch 196/196\n",
      "31/31 [==============================] - 4s 138ms/step - loss: 0.2531 - categorical_accuracy: 0.9146 - val_loss: 0.1318 - val_categorical_accuracy: 0.9583\n",
      "Epoch 197/197\n",
      "31/31 [==============================] - 4s 139ms/step - loss: 0.2787 - categorical_accuracy: 0.9064 - val_loss: 0.2386 - val_categorical_accuracy: 0.9444\n",
      "Epoch 198/198\n",
      "31/31 [==============================] - 4s 140ms/step - loss: 0.2624 - categorical_accuracy: 0.9059 - val_loss: 0.1722 - val_categorical_accuracy: 0.9630\n",
      "Epoch 199/199\n",
      "31/31 [==============================] - 4s 143ms/step - loss: 0.2236 - categorical_accuracy: 0.9249 - val_loss: 0.3418 - val_categorical_accuracy: 0.9537\n",
      "Epoch 200/200\n",
      "31/31 [==============================] - 4s 142ms/step - loss: 0.2608 - categorical_accuracy: 0.9234 - val_loss: 0.8605 - val_categorical_accuracy: 0.8102\n",
      "Epoch 201/201\n",
      "31/31 [==============================] - 4s 141ms/step - loss: 0.4019 - categorical_accuracy: 0.8771 - val_loss: 0.1834 - val_categorical_accuracy: 0.9491\n",
      "Epoch 202/202\n",
      "38/38 [==============================] - 5s 139ms/step - loss: 0.3061 - categorical_accuracy: 0.9096 - val_loss: 0.1740 - val_categorical_accuracy: 0.9630\n",
      "Epoch 203/203\n",
      "31/31 [==============================] - 4s 142ms/step - loss: 0.2501 - categorical_accuracy: 0.9141 - val_loss: 0.4034 - val_categorical_accuracy: 0.9120\n",
      "Epoch 204/204\n",
      "31/31 [==============================] - 4s 142ms/step - loss: 0.2856 - categorical_accuracy: 0.9110 - val_loss: 0.1934 - val_categorical_accuracy: 0.9583\n",
      "Epoch 205/205\n",
      "16/16 [==============================] - 2s 146ms/step - loss: 0.2526 - categorical_accuracy: 0.9177 - val_loss: 0.2039 - val_categorical_accuracy: 0.9398\n",
      "Epoch 206/206\n",
      "16/16 [==============================] - 2s 146ms/step - loss: 0.1839 - categorical_accuracy: 0.9475 - val_loss: 0.1471 - val_categorical_accuracy: 0.9583\n",
      "Epoch 207/207\n",
      "16/16 [==============================] - 2s 147ms/step - loss: 0.2221 - categorical_accuracy: 0.9239 - val_loss: 0.2002 - val_categorical_accuracy: 0.9259\n",
      "Epoch 208/208\n",
      "16/16 [==============================] - 2s 146ms/step - loss: 0.2195 - categorical_accuracy: 0.9342 - val_loss: 0.2014 - val_categorical_accuracy: 0.9398\n",
      "Epoch 209/209\n",
      "16/16 [==============================] - 2s 146ms/step - loss: 0.3843 - categorical_accuracy: 0.8920 - val_loss: 0.3776 - val_categorical_accuracy: 0.8889\n",
      "Epoch 210/210\n",
      "16/16 [==============================] - 2s 150ms/step - loss: 0.4644 - categorical_accuracy: 0.8591 - val_loss: 0.2555 - val_categorical_accuracy: 0.9352\n",
      "Epoch 211/211\n",
      "16/16 [==============================] - 2s 147ms/step - loss: 0.4158 - categorical_accuracy: 0.8714 - val_loss: 0.2745 - val_categorical_accuracy: 0.9213\n",
      "Epoch 212/212\n",
      "16/16 [==============================] - 2s 147ms/step - loss: 0.3401 - categorical_accuracy: 0.9043 - val_loss: 0.3167 - val_categorical_accuracy: 0.9120\n",
      "Epoch 213/213\n",
      "38/38 [==============================] - 5s 140ms/step - loss: 0.3685 - categorical_accuracy: 0.8938 - val_loss: 0.1688 - val_categorical_accuracy: 0.9491\n",
      "Epoch 214/214\n",
      "38/38 [==============================] - 5s 140ms/step - loss: 0.2668 - categorical_accuracy: 0.9083 - val_loss: 0.1980 - val_categorical_accuracy: 0.9398\n",
      "Epoch 215/215\n",
      "31/31 [==============================] - 4s 140ms/step - loss: 0.2468 - categorical_accuracy: 0.9131 - val_loss: 0.2558 - val_categorical_accuracy: 0.9259\n",
      "Epoch 216/216\n",
      "31/31 [==============================] - 4s 141ms/step - loss: 0.2428 - categorical_accuracy: 0.9213 - val_loss: 0.2042 - val_categorical_accuracy: 0.9491\n",
      "Epoch 217/217\n",
      "16/16 [==============================] - 2s 149ms/step - loss: 0.2587 - categorical_accuracy: 0.9156 - val_loss: 0.1090 - val_categorical_accuracy: 0.9630\n",
      "Epoch 218/218\n",
      "16/16 [==============================] - 2s 145ms/step - loss: 0.2867 - categorical_accuracy: 0.9105 - val_loss: 0.1847 - val_categorical_accuracy: 0.9352\n",
      "Epoch 219/219\n",
      "16/16 [==============================] - 2s 146ms/step - loss: 0.2444 - categorical_accuracy: 0.9177 - val_loss: 0.1316 - val_categorical_accuracy: 0.9537\n",
      "Epoch 220/220\n",
      "16/16 [==============================] - 2s 153ms/step - loss: 0.2216 - categorical_accuracy: 0.9311 - val_loss: 0.1513 - val_categorical_accuracy: 0.9491\n",
      "Epoch 221/221\n",
      "16/16 [==============================] - 2s 146ms/step - loss: 0.2873 - categorical_accuracy: 0.9095 - val_loss: 0.1498 - val_categorical_accuracy: 0.9398\n",
      "Epoch 222/222\n",
      "16/16 [==============================] - 2s 148ms/step - loss: 0.2369 - categorical_accuracy: 0.9228 - val_loss: 0.1094 - val_categorical_accuracy: 0.9583\n",
      "Epoch 223/223\n",
      "16/16 [==============================] - 2s 144ms/step - loss: 0.1933 - categorical_accuracy: 0.9321 - val_loss: 0.1009 - val_categorical_accuracy: 0.9583\n",
      "Epoch 224/224\n",
      "16/16 [==============================] - 2s 145ms/step - loss: 0.1836 - categorical_accuracy: 0.9393 - val_loss: 0.1167 - val_categorical_accuracy: 0.9630\n",
      "Epoch 225/225\n",
      "38/38 [==============================] - 5s 138ms/step - loss: 0.2213 - categorical_accuracy: 0.9279 - val_loss: 0.0807 - val_categorical_accuracy: 0.9769\n",
      "Epoch 226/226\n",
      "38/38 [==============================] - 5s 140ms/step - loss: 0.2416 - categorical_accuracy: 0.9233 - val_loss: 0.0893 - val_categorical_accuracy: 0.9722\n",
      "Epoch 227/227\n",
      "31/31 [==============================] - 4s 140ms/step - loss: 0.2068 - categorical_accuracy: 0.9326 - val_loss: 0.0842 - val_categorical_accuracy: 0.9769\n",
      "Epoch 228/228\n",
      "31/31 [==============================] - 4s 140ms/step - loss: 0.1997 - categorical_accuracy: 0.9336 - val_loss: 0.0830 - val_categorical_accuracy: 0.9769\n",
      "Epoch 229/229\n",
      "16/16 [==============================] - 2s 146ms/step - loss: 0.2459 - categorical_accuracy: 0.9259 - val_loss: 0.1510 - val_categorical_accuracy: 0.9537\n",
      "Epoch 230/230\n",
      "16/16 [==============================] - 2s 153ms/step - loss: 0.3042 - categorical_accuracy: 0.9002 - val_loss: 0.1695 - val_categorical_accuracy: 0.9491\n",
      "Epoch 231/231\n",
      "16/16 [==============================] - 2s 147ms/step - loss: 0.2269 - categorical_accuracy: 0.9218 - val_loss: 0.1099 - val_categorical_accuracy: 0.9630\n",
      "Epoch 232/232\n",
      "16/16 [==============================] - 2s 144ms/step - loss: 0.1764 - categorical_accuracy: 0.9352 - val_loss: 0.0979 - val_categorical_accuracy: 0.9583\n",
      "Epoch 233/233\n",
      "16/16 [==============================] - 2s 146ms/step - loss: 0.2314 - categorical_accuracy: 0.9280 - val_loss: 0.0926 - val_categorical_accuracy: 0.9815\n",
      "Epoch 234/234\n",
      "16/16 [==============================] - 2s 145ms/step - loss: 0.1856 - categorical_accuracy: 0.9465 - val_loss: 0.0711 - val_categorical_accuracy: 0.9861\n",
      "Epoch 235/235\n",
      "16/16 [==============================] - 2s 148ms/step - loss: 0.1929 - categorical_accuracy: 0.9342 - val_loss: 0.1215 - val_categorical_accuracy: 0.9630\n",
      "Epoch 236/236\n",
      "16/16 [==============================] - 2s 145ms/step - loss: 0.1795 - categorical_accuracy: 0.9352 - val_loss: 0.0892 - val_categorical_accuracy: 0.9630\n",
      "Epoch 237/237\n",
      "38/38 [==============================] - 5s 139ms/step - loss: 0.2041 - categorical_accuracy: 0.9421 - val_loss: 0.0694 - val_categorical_accuracy: 0.9769\n",
      "Epoch 238/238\n",
      "38/38 [==============================] - 5s 142ms/step - loss: 0.2309 - categorical_accuracy: 0.9312 - val_loss: 0.0949 - val_categorical_accuracy: 0.9769\n",
      "Epoch 239/239\n",
      "31/31 [==============================] - 4s 141ms/step - loss: 0.2183 - categorical_accuracy: 0.9280 - val_loss: 0.0988 - val_categorical_accuracy: 0.9630\n",
      "Epoch 240/240\n",
      "31/31 [==============================] - 4s 143ms/step - loss: 0.1929 - categorical_accuracy: 0.9393 - val_loss: 0.0883 - val_categorical_accuracy: 0.9676\n",
      "Epoch 241/241\n",
      "16/16 [==============================] - 2s 144ms/step - loss: 0.1863 - categorical_accuracy: 0.9444 - val_loss: 0.0875 - val_categorical_accuracy: 0.9722\n",
      "Epoch 242/242\n",
      "16/16 [==============================] - 2s 147ms/step - loss: 0.1666 - categorical_accuracy: 0.9414 - val_loss: 0.0589 - val_categorical_accuracy: 0.9861\n",
      "Epoch 243/243\n",
      "16/16 [==============================] - 2s 146ms/step - loss: 0.2002 - categorical_accuracy: 0.9321 - val_loss: 0.3042 - val_categorical_accuracy: 0.9398\n",
      "Epoch 244/244\n",
      "16/16 [==============================] - 2s 145ms/step - loss: 0.2324 - categorical_accuracy: 0.9383 - val_loss: 0.1629 - val_categorical_accuracy: 0.9444\n",
      "Epoch 245/245\n",
      "16/16 [==============================] - 2s 146ms/step - loss: 0.2655 - categorical_accuracy: 0.9187 - val_loss: 0.0751 - val_categorical_accuracy: 0.9583\n",
      "Epoch 246/246\n",
      "16/16 [==============================] - 2s 146ms/step - loss: 0.2352 - categorical_accuracy: 0.9270 - val_loss: 0.1969 - val_categorical_accuracy: 0.9583\n",
      "Epoch 247/247\n",
      "16/16 [==============================] - 2s 146ms/step - loss: 0.2975 - categorical_accuracy: 0.9136 - val_loss: 0.2240 - val_categorical_accuracy: 0.9259\n",
      "Epoch 248/248\n",
      "16/16 [==============================] - 2s 145ms/step - loss: 0.3286 - categorical_accuracy: 0.8981 - val_loss: 0.3684 - val_categorical_accuracy: 0.9306\n",
      "Epoch 249/249\n",
      "38/38 [==============================] - 6s 150ms/step - loss: 0.2174 - categorical_accuracy: 0.9388 - val_loss: 0.0531 - val_categorical_accuracy: 0.9769\n",
      "Epoch 250/250\n",
      "38/38 [==============================] - 5s 139ms/step - loss: 0.2086 - categorical_accuracy: 0.9404 - val_loss: 0.0959 - val_categorical_accuracy: 0.9676\n",
      "Epoch 251/251\n",
      "31/31 [==============================] - 4s 140ms/step - loss: 0.1895 - categorical_accuracy: 0.9372 - val_loss: 0.0701 - val_categorical_accuracy: 0.9815\n",
      "Epoch 252/252\n",
      "31/31 [==============================] - 4s 140ms/step - loss: 0.1642 - categorical_accuracy: 0.9480 - val_loss: 0.0601 - val_categorical_accuracy: 0.9907\n",
      "Epoch 253/253\n",
      "31/31 [==============================] - 4s 140ms/step - loss: 0.1542 - categorical_accuracy: 0.9522 - val_loss: 0.0609 - val_categorical_accuracy: 0.9815\n",
      "Epoch 254/254\n",
      "31/31 [==============================] - 4s 142ms/step - loss: 0.1362 - categorical_accuracy: 0.9542 - val_loss: 0.0689 - val_categorical_accuracy: 0.9676\n",
      "Epoch 255/255\n",
      "31/31 [==============================] - 5s 151ms/step - loss: 0.1483 - categorical_accuracy: 0.9470 - val_loss: 0.1336 - val_categorical_accuracy: 0.9583\n",
      "Epoch 256/256\n",
      "31/31 [==============================] - 4s 140ms/step - loss: 0.1854 - categorical_accuracy: 0.9460 - val_loss: 0.1036 - val_categorical_accuracy: 0.9722\n",
      "Epoch 257/257\n",
      "31/31 [==============================] - 5s 155ms/step - loss: 0.1966 - categorical_accuracy: 0.9414 - val_loss: 0.2239 - val_categorical_accuracy: 0.9630\n",
      "Epoch 258/258\n",
      "31/31 [==============================] - 4s 139ms/step - loss: 0.1731 - categorical_accuracy: 0.9491 - val_loss: 0.0549 - val_categorical_accuracy: 0.9861\n",
      "Epoch 259/259\n",
      "31/31 [==============================] - 4s 140ms/step - loss: 0.1613 - categorical_accuracy: 0.9444 - val_loss: 0.0714 - val_categorical_accuracy: 0.9861\n",
      "Epoch 260/260\n",
      "31/31 [==============================] - 4s 138ms/step - loss: 0.1555 - categorical_accuracy: 0.9522 - val_loss: 0.2944 - val_categorical_accuracy: 0.9444\n",
      "Epoch 261/261\n",
      "31/31 [==============================] - 4s 139ms/step - loss: 0.2430 - categorical_accuracy: 0.9306 - val_loss: 0.2579 - val_categorical_accuracy: 0.9491\n",
      "Epoch 262/262\n",
      "31/31 [==============================] - 4s 138ms/step - loss: 0.1993 - categorical_accuracy: 0.9444 - val_loss: 0.1236 - val_categorical_accuracy: 0.9676\n",
      "Epoch 263/263\n",
      "31/31 [==============================] - 4s 142ms/step - loss: 0.1629 - categorical_accuracy: 0.9511 - val_loss: 0.1566 - val_categorical_accuracy: 0.9583\n",
      "Epoch 264/264\n",
      "31/31 [==============================] - 4s 138ms/step - loss: 0.2232 - categorical_accuracy: 0.9295 - val_loss: 0.1195 - val_categorical_accuracy: 0.9537\n",
      "Epoch 265/265\n",
      "31/31 [==============================] - 4s 142ms/step - loss: 0.2019 - categorical_accuracy: 0.9429 - val_loss: 0.1014 - val_categorical_accuracy: 0.9676\n",
      "Epoch 266/266\n",
      "31/31 [==============================] - 4s 138ms/step - loss: 0.1719 - categorical_accuracy: 0.9522 - val_loss: 0.0711 - val_categorical_accuracy: 0.9722\n",
      "Epoch 267/267\n",
      "31/31 [==============================] - 4s 139ms/step - loss: 0.1501 - categorical_accuracy: 0.9522 - val_loss: 0.1023 - val_categorical_accuracy: 0.9630\n",
      "Epoch 268/268\n",
      "31/31 [==============================] - 4s 140ms/step - loss: 0.1385 - categorical_accuracy: 0.9552 - val_loss: 0.0938 - val_categorical_accuracy: 0.9676\n",
      "Epoch 269/269\n",
      "31/31 [==============================] - 4s 141ms/step - loss: 0.1594 - categorical_accuracy: 0.9496 - val_loss: 0.1960 - val_categorical_accuracy: 0.9676\n",
      "Epoch 270/270\n",
      "31/31 [==============================] - 4s 139ms/step - loss: 0.1350 - categorical_accuracy: 0.9547 - val_loss: 0.0665 - val_categorical_accuracy: 0.9907\n",
      "Epoch 271/271\n",
      "31/31 [==============================] - 4s 140ms/step - loss: 0.1475 - categorical_accuracy: 0.9537 - val_loss: 0.0804 - val_categorical_accuracy: 0.9769\n",
      "Epoch 272/272\n",
      "31/31 [==============================] - 4s 139ms/step - loss: 0.2087 - categorical_accuracy: 0.9362 - val_loss: 0.0920 - val_categorical_accuracy: 0.9769\n",
      "Epoch 273/273\n",
      "31/31 [==============================] - 4s 139ms/step - loss: 0.1664 - categorical_accuracy: 0.9542 - val_loss: 0.1739 - val_categorical_accuracy: 0.9815\n",
      "Epoch 274/274\n",
      "31/31 [==============================] - 4s 140ms/step - loss: 0.1603 - categorical_accuracy: 0.9496 - val_loss: 0.1490 - val_categorical_accuracy: 0.9583\n",
      "Epoch 275/275\n",
      "31/31 [==============================] - 4s 138ms/step - loss: 0.1227 - categorical_accuracy: 0.9599 - val_loss: 0.1340 - val_categorical_accuracy: 0.9630\n",
      "Epoch 276/276\n",
      "31/31 [==============================] - 4s 140ms/step - loss: 0.1423 - categorical_accuracy: 0.9583 - val_loss: 0.2756 - val_categorical_accuracy: 0.9676\n",
      "Epoch 277/277\n",
      "31/31 [==============================] - 4s 139ms/step - loss: 0.1918 - categorical_accuracy: 0.9434 - val_loss: 0.1769 - val_categorical_accuracy: 0.9722\n",
      "Epoch 278/278\n",
      "31/31 [==============================] - 4s 138ms/step - loss: 0.1536 - categorical_accuracy: 0.9568 - val_loss: 0.1947 - val_categorical_accuracy: 0.9722\n",
      "Epoch 279/279\n",
      "31/31 [==============================] - 4s 137ms/step - loss: 0.1295 - categorical_accuracy: 0.9604 - val_loss: 0.1020 - val_categorical_accuracy: 0.9769\n",
      "Epoch 280/280\n",
      "31/31 [==============================] - 4s 142ms/step - loss: 0.1839 - categorical_accuracy: 0.9388 - val_loss: 0.2136 - val_categorical_accuracy: 0.9583\n",
      "Epoch 281/281\n",
      "31/31 [==============================] - 4s 139ms/step - loss: 0.1579 - categorical_accuracy: 0.9537 - val_loss: 0.0854 - val_categorical_accuracy: 0.9815\n",
      "Epoch 282/282\n",
      "31/31 [==============================] - 4s 141ms/step - loss: 0.1186 - categorical_accuracy: 0.9609 - val_loss: 0.2588 - val_categorical_accuracy: 0.9815\n"
     ]
    }
   ],
   "source": [
    "loss, val_loss, cat_accuracy = [], [], []\n",
    "model.compile(optimizer=Adam(learning_rate=1e-4), loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "for _epochs in range(400):\n",
    "    count = _epochs % 12\n",
    "    if (count < 10 and (_epochs < 150 or (_epochs < 250 and _epochs > 200))):\n",
    "        if (count < 4):\n",
    "            x_train__ = x_train_[0]\n",
    "            y_train__ = y_train_[0]\n",
    "        elif (count < 8):\n",
    "            x_train__ = x_train_[1]\n",
    "            y_train__ = y_train_[1]\n",
    "        elif (count < 10):\n",
    "            x_train__ = X_train_2\n",
    "            y_train__ = y_train_2\n",
    "    else :\n",
    "        x_train__ = X_train\n",
    "        y_train__ = y_train\n",
    "    model_train = model.fit(x_train__, y_train__, epochs=_epochs+1, batch_size=64,validation_data=(X_val,y_val),initial_epoch=_epochs)\n",
    "    _loss = model_train.history['loss']\n",
    "    _val_loss = model_train.history['val_loss']\n",
    "    _cat_accuracy = model_train.history['categorical_accuracy']\n",
    "    loss.append(_loss[len(_loss)-1])\n",
    "    val_loss.append(_val_loss[len(_loss)-1])\n",
    "    cat_accuracy.append(_cat_accuracy[len(_loss)-1])\n",
    "    if (loss[len(loss)-1] < val_loss[len(loss)-1] and cat_accuracy[len(loss)-1] > 0.96):\n",
    "        break\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_14 (LSTM)              (None, 4, 64)             28928     \n",
      "                                                                 \n",
      " dropout_21 (Dropout)        (None, 4, 64)             0         \n",
      "                                                                 \n",
      " lstm_15 (LSTM)              (None, 4, 128)            98816     \n",
      "                                                                 \n",
      " lstm_16 (LSTM)              (None, 4, 64)             49408     \n",
      "                                                                 \n",
      " flatten_6 (Flatten)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 64)                16448     \n",
      "                                                                 \n",
      " dropout_22 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dropout_23 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 195,746\n",
      "Trainable params: 195,746\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get training and test loss histories\n",
    "training_loss = model_train.history['loss']\n",
    "test_loss = model_train.history['val_loss']\n",
    "avg = []\n",
    "\n",
    "for i in range(len(training_loss)):\n",
    "    sum = training_loss[i]+test_loss[i]\n",
    "    avg.append(sum/2)\n",
    "\n",
    "# avg = np.array([training_loss, test_loss])\n",
    "# np.average(avg)\n",
    "\n",
    "# Create count of the number of epochs\n",
    "epoch_count = range(1, len(training_loss) + 1)\n",
    "\n",
    "# Visualize loss history\n",
    "plt.plot(epoch_count, training_loss, 'r--')\n",
    "plt.plot(epoch_count, test_loss, 'b-')\n",
    "plt.plot(epoch_count, avg, 'g-')\n",
    "plt.legend(['Training Loss', 'Test Loss', 'Average'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()\n",
    "# print(avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 2s 12ms/step\n"
     ]
    }
   ],
   "source": [
    "res = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'continue'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions[np.argmax(res[3])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'continue'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions[np.argmax(y_test[3])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Save Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model_start_detection.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('model_2.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Evaluation using Confusion Matrix and Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 2s 11ms/step\n"
     ]
    }
   ],
   "source": [
    "yhat = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrue = np.argmax(y_test, axis=1).tolist()\n",
    "yhat = np.argmax(yhat, axis=1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "confussionMatrix = multilabel_confusion_matrix(ytrue, yhat)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confussionMatrix = confusion_matrix(ytrue, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[228   0]\n",
      "  [  0  12]]\n",
      "\n",
      " [[222   0]\n",
      "  [  2  16]]\n",
      "\n",
      " [[226   0]\n",
      "  [  1  13]]\n",
      "\n",
      " [[224   2]\n",
      "  [  0  14]]\n",
      "\n",
      " [[220   5]\n",
      "  [  0  15]]\n",
      "\n",
      " [[227   0]\n",
      "  [  2  11]]\n",
      "\n",
      " [[226   1]\n",
      "  [  1  12]]\n",
      "\n",
      " [[217   0]\n",
      "  [  2  21]]\n",
      "\n",
      " [[223   5]\n",
      "  [  0  12]]\n",
      "\n",
      " [[220   0]\n",
      "  [  2  18]]\n",
      "\n",
      " [[230   1]\n",
      "  [  0   9]]\n",
      "\n",
      " [[222   2]\n",
      "  [  4  12]]\n",
      "\n",
      " [[224   2]\n",
      "  [  2  12]]\n",
      "\n",
      " [[223   0]\n",
      "  [  0  17]]\n",
      "\n",
      " [[223   2]\n",
      "  [  4  11]]\n",
      "\n",
      " [[225   0]\n",
      "  [  0  15]]]\n"
     ]
    }
   ],
   "source": [
    "print(confussionMatrix)\n",
    "with open('confussionMatrixModel_2.txt', 'w') as f:\n",
    "    f.write(str(confussionMatrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9711111111111111\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(ytrue, yhat)\n",
    "print(accuracy)\n",
    "# with open('accuracyScoreModel_2.txt', 'w') as f:\n",
    "#     f.write(str(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       start       1.00      0.94      0.97       421\n",
      "    continue       0.95      1.00      0.97       479\n",
      "\n",
      "    accuracy                           0.97       900\n",
      "   macro avg       0.97      0.97      0.97       900\n",
      "weighted avg       0.97      0.97      0.97       900\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print('\\nClassification Report\\n')\n",
    "print(classification_report(ytrue, yhat, target_names=actions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "cm_df = pd.DataFrame(confussionMatrix,\n",
    "                     index = actions, \n",
    "                     columns = actions)\n",
    "\n",
    "import seaborn as sns\n",
    "#Plotting the confusion matrix\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(cm_df, annot=True)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('Actual Values')\n",
    "plt.xlabel('Predicted Values')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11. Test in Real Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [(245,117,16), (117,245,16), (16,117,245)]\n",
    "def prob_viz(res, actions, input_frame, colors):\n",
    "    output_frame = input_frame.copy()\n",
    "    for num, prob in enumerate(res):\n",
    "        # cv2.rectangle(output_frame, (0,60+num*40), (int(prob*100), 90+num*40), colors[num], -1)\n",
    "        cv2.putText(output_frame, actions[num], (50,50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2, cv2.LINE_AA)\n",
    "        \n",
    "    return output_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "only size-1 arrays can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\haika\\Documents\\GitHub\\realtime_bisindo_sibi_translator\\Action Detection Refined.ipynb Cell 70\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/haika/Documents/GitHub/realtime_bisindo_sibi_translator/Action%20Detection%20Refined.ipynb#Y125sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m plt\u001b[39m.\u001b[39mfigure(figsize\u001b[39m=\u001b[39m(\u001b[39m18\u001b[39m,\u001b[39m18\u001b[39m))\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/haika/Documents/GitHub/realtime_bisindo_sibi_translator/Action%20Detection%20Refined.ipynb#Y125sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m plt\u001b[39m.\u001b[39mimshow(prob_viz(res, actions, image, colors))\n",
      "\u001b[1;32mc:\\Users\\haika\\Documents\\GitHub\\realtime_bisindo_sibi_translator\\Action Detection Refined.ipynb Cell 70\u001b[0m in \u001b[0;36mprob_viz\u001b[1;34m(res, actions, input_frame, colors)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/haika/Documents/GitHub/realtime_bisindo_sibi_translator/Action%20Detection%20Refined.ipynb#Y125sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m output_frame \u001b[39m=\u001b[39m input_frame\u001b[39m.\u001b[39mcopy()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/haika/Documents/GitHub/realtime_bisindo_sibi_translator/Action%20Detection%20Refined.ipynb#Y125sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfor\u001b[39;00m num, prob \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(res):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/haika/Documents/GitHub/realtime_bisindo_sibi_translator/Action%20Detection%20Refined.ipynb#Y125sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     cv2\u001b[39m.\u001b[39mrectangle(output_frame, (\u001b[39m0\u001b[39m,\u001b[39m60\u001b[39m\u001b[39m+\u001b[39mnum\u001b[39m*\u001b[39m\u001b[39m40\u001b[39m), (\u001b[39mint\u001b[39;49m(prob\u001b[39m*\u001b[39;49m\u001b[39m100\u001b[39;49m), \u001b[39m90\u001b[39m\u001b[39m+\u001b[39mnum\u001b[39m*\u001b[39m\u001b[39m40\u001b[39m), colors[num], \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/haika/Documents/GitHub/realtime_bisindo_sibi_translator/Action%20Detection%20Refined.ipynb#Y125sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     cv2\u001b[39m.\u001b[39mputText(output_frame, actions[num], (\u001b[39m0\u001b[39m, \u001b[39m85\u001b[39m\u001b[39m+\u001b[39mnum\u001b[39m*\u001b[39m\u001b[39m40\u001b[39m), cv2\u001b[39m.\u001b[39mFONT_HERSHEY_SIMPLEX, \u001b[39m1\u001b[39m, (\u001b[39m255\u001b[39m,\u001b[39m255\u001b[39m,\u001b[39m255\u001b[39m), \u001b[39m2\u001b[39m, cv2\u001b[39m.\u001b[39mLINE_AA)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/haika/Documents/GitHub/realtime_bisindo_sibi_translator/Action%20Detection%20Refined.ipynb#Y125sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mreturn\u001b[39;00m output_frame\n",
      "\u001b[1;31mTypeError\u001b[0m: only size-1 arrays can be converted to Python scalars"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1296x1296 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(18,18))\n",
    "plt.imshow(prob_viz(res, actions, image, colors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "start\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "start\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "start\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "start\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "start\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "start\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "start\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "start\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "start\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "start\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "start\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "start\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "start\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "start\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "start\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "start\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "start\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "start\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "start\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "start\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "start\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "start\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "start\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "start\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "start\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "start\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "start\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "start\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "start\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "start\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "start\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "start\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "start\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "start\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "start\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "start\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "start\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "start\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "start\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "start\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "start\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "start\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "start\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 105ms/step\n",
      "start\n"
     ]
    }
   ],
   "source": [
    "# 1. New detection variables\n",
    "sequence = []\n",
    "sentence = []\n",
    "predictions = []\n",
    "threshold = 0.5\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "# Set mediapipe model \n",
    "with mp_detect.mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    while cap.isOpened():\n",
    "\n",
    "        # Read feed\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # Make detections\n",
    "        image, results = mp_detect.mediapipe_detection(frame, holistic)\n",
    "        print(results)\n",
    "        \n",
    "        # Draw landmarks\n",
    "        mp_detect.draw_styled_landmarks(image, results)\n",
    "        \n",
    "        # 2. Prediction logic\n",
    "        keypoints = mp_detect.extract_keypoints_only_handpose(results)\n",
    "        sequence.append(keypoints)\n",
    "        sequence = sequence[-4:]\n",
    "        \n",
    "        if len(sequence) == 4:\n",
    "            res = model.predict(np.expand_dims(sequence, axis=0))[0]\n",
    "            print(actions[np.argmax(res)])\n",
    "            predictions.append(np.argmax(res))\n",
    "            \n",
    "            \n",
    "        #3. Viz logic\n",
    "            # if np.unique(predictions[-10:])[0]==np.argmax(res): \n",
    "            #     if res[np.argmax(res)] > threshold: \n",
    "                    \n",
    "            #         if len(sentence) > 0: \n",
    "            #             if actions[np.argmax(res)] != sentence[-1]:\n",
    "            #                 sentence.append(actions[np.argmax(res)])\n",
    "            #         else:\n",
    "            sentence.append(actions[np.argmax(res)])\n",
    "\n",
    "            if len(sentence) > 5: \n",
    "                sentence = sentence[-5:]\n",
    "\n",
    "            # Viz probabilities\n",
    "            # image = prob_viz(res, actions, image, colors)\n",
    "            \n",
    "        # cv2.rectangle(image, (0,0), (320, 40), (245, 117, 16), -1)\n",
    "        cv2.putText(image, ' '.join(sentence), (3,30), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "        \n",
    "        # Show to screen\n",
    "        cv2.imshow('OpenCV Feed', image)\n",
    "\n",
    "        # Break gracefully\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "d428c2a1e34a88b46480b35490d30f1e50265fea0856e59da1459dd84013c8a8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
